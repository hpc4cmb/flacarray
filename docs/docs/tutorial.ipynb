{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fc20d7-44b5-4fc6-ae0d-e5863f16102b",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "\n",
    "The `flacarray` package has tools for working with compressed arrays in memory, as well as saving and loading those to several file formats.  This tutorial makes use of some interactive helper functions in the `flacarray.demo` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4666df3-4e3f-4e15-a05d-48152eb50e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py # For optional I/O operations\n",
    "import zarr # For optional I/O operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c809b72-8e51-4a3d-abc0-a37f78e75d95",
   "metadata": {},
   "source": [
    "## `FlacArray` - Compressed Arrays in Memory\n",
    "\n",
    "The primary class for working with compressed arrays in memory is the `FlacArray` class.  You can construct one of these from a numpy array with a class method.  First create some fake data in a numpy array for testing.  This is a small 3-D array and the final dimension is always the one that is compressed.  This last dimension should consist of \"streams\" of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99a31f6-03ad-4b0b-bb30-e16253038e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flacarray import FlacArray, demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb6018-8e07-4f89-a532-a619e890c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3D array where the last dimension is the \"streams\" we are compressing.\n",
    "arr = demo.create_fake_data((4, 3, 10000))\n",
    "# How large is this in memory?\n",
    "print(f\"Input array is {arr.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92daf80f-9b28-4648-8105-f1ffb91c43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot these streams\n",
    "demo.plot_data(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67065c-a741-4f87-a0fa-4ff184df012e",
   "metadata": {},
   "source": [
    "### Create From Array\n",
    "\n",
    "Now create a `FlacArray` from this.  Since this is floating point data, the streams will always be truncated to 32 bits and by default each bit value will be chosen so that the peak-to-peak range of the signal spans the available $2^{30}$ bits available for the FLAC stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c764f4-62b0-4258-b6cc-d2e492aba423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a compressed array\n",
    "flcarr = FlacArray.from_array(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43958b2d-7a35-436a-97fd-947f5c228204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properties of the compressed array\n",
    "print(flcarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d859948-6593-4ebb-9e8e-8367547364a8",
   "metadata": {},
   "source": [
    "### Decompress Back to Array\n",
    "\n",
    "Now decompress back to a numpy array.  The results will only be bitwise identical for arrays consisting of 32 bit integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1d4ddb-69aa-4976-ae1c-d372091149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restore back to an array\n",
    "restored = flcarr.to_array()\n",
    "demo.plot_data(restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46cf1b5-393f-41b2-a7e2-3c5293708f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the residual\n",
    "residual = restored - arr\n",
    "demo.plot_data(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1123fa1-26cb-41e7-9f03-6bbc7b2075ef",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "\n",
    "A subset of the full array can be decompressed on the fly.  Any fancy array indexing can be used for the leading dimensions, but only contiguous slices or individual samples are supported in the last dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac2ec0-048a-4d30-919c-64d09f742489",
   "metadata": {},
   "outputs": [],
   "source": [
    "subarr = flcarr[1:2, :, 200:300]\n",
    "demo.plot_data(subarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1fa844-bcdf-4d80-a8e0-bc97ba0d1f9c",
   "metadata": {},
   "source": [
    "### Writing and Reading\n",
    "\n",
    "The `FlacArray` class has methods to write the internal compressed data and metadata to both h5py and zarr groups.  The data members written to these file formats are simple arrays and scalars.  Supporting other formats in the future would be straightforward.  When decompressing data from disk, you can choose to decompress only a subset of the streams.  Here is an example writing the compressed array to HDF5 and loading it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be35ecd-ea5b-4685-a340-41ee63449ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"flcarr.h5\", \"w\") as hf:\n",
    "    flcarr.write_hdf5(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424052c-81ff-4259-9ff8-4e67ae148a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can load this back into a new FlacArray using a class method\n",
    "with h5py.File(\"flcarr.h5\", \"r\") as hf:\n",
    "    new_flcarr = FlacArray.read_hdf5(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcd59e-2618-4d66-b7e0-750da11c8a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The compressed representations should be equal...\n",
    "print(new_flcarr == flcarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6aaec7-2453-456f-8b60-cfa9fa7a7711",
   "metadata": {},
   "source": [
    "You can also load in just a subset of the streams using a \"keep\" mask.  This is a boolean array with the same shape as the leading dimensions of the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d69e7-3c2b-4945-b1b9-7afdb869bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "leading_shape = arr.shape[:-1]\n",
    "keep = np.zeros(leading_shape, dtype=bool)\n",
    "# Select the first and last stream on the second row\n",
    "keep[1, 0] = True\n",
    "keep[1, -1] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d0115-da77-48e0-a05e-a5c5243e29e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just these streams\n",
    "with h5py.File(\"flcarr.h5\", \"r\") as hf:\n",
    "    sub_flcarr = FlacArray.read_hdf5(hf, keep=keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa9a29-7484-4769-960c-08dafa053646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress and plot\n",
    "demo.plot_data(sub_flcarr.to_array())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7d8cc-59ce-4689-93b4-4b97e9945ed9",
   "metadata": {},
   "source": [
    "## Direct I/O and Compression of Numpy Arrays\n",
    "\n",
    "For some use cases, there is no need to keep the full compressed data in memory (in a `FlacArray`).  Instead, a normal numpy array is compressed when writing to a file and decompressed back into a numpy array when reading.  The package has high-level functions for performing this kind of operation.  When decompressing, a subset of streams can be loaded from disk, and then a sample range can be specified when doing the decompression.\n",
    "\n",
    "### HDF5\n",
    "\n",
    "The `hdf5` sub-module has helper functions for direct I/O to HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f2152d-ae2e-4f6c-ac7c-39586a5cf198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flacarray.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725ac30-367d-49ef-8cbc-2ff763f0f8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a numpy array directly to HDF5.  This is equivalent to doing:\n",
    "#\n",
    "# temp = FlacArray.from_array(arr)\n",
    "# with h5py.File(\"test.h5\", \"w\") as hf:\n",
    "#     temp.write_hdf5(hf)\n",
    "#\n",
    "with h5py.File(\"test.h5\", \"w\") as hf:\n",
    "    flacarray.hdf5.write_array(arr, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722a5eb0-f9df-4381-b7a2-dc83c52b09cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"test.h5\", \"r\") as hf:\n",
    "    restored = flacarray.hdf5.read_array(hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdf5e2-d50e-4239-9910-565968e2c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.plot_data(restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3afc237-7c41-4f44-b17a-284714446be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only a subset of streams and a slice of samples in those streams.\n",
    "# This is equivalent to the following code:\n",
    "#\n",
    "# with h5py.File(\"test.h5\", \"r\") as hf:\n",
    "#    restored = FlacArray.read_hdf5(hf, keep=keep)\n",
    "#    sub_restored = restored[:, 200:300]\n",
    "#\n",
    "with h5py.File(\"test.h5\", \"r\") as hf:\n",
    "    sub_restored = flacarray.hdf5.read_array(hf, keep=keep, stream_slice=slice(200, 300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9287ad30-aec0-4141-bae8-6d5289561cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.plot_data(sub_restored)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f700dc-3625-4dd4-91fb-c40f213de564",
   "metadata": {},
   "source": [
    "### Zarr\n",
    "\n",
    "The zarr package provides an h5py-like interface for creating groups with attributes and \"datasets\" (arrays) on disk.  Given an existing `zarr.hierarchy.Group`, you can compress and write an array and then load it back in.  This is almost identical to the HDF5 syntax above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337acf-3544-43b9-b9f4-548b51837ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flacarray.zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ed17a9-39c7-416d-9e0a-45c48333572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zarr.open_group(\"test.zarr\", mode=\"w\") as zf:\n",
    "    flacarray.zarr.write_array(arr, zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c11124-beb4-46e7-b994-930e1e225cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zarr.open_group(\"test.zarr\", mode=\"r\") as zf:\n",
    "    restored = flacarray.zarr.read_array(zf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568892ad-e954-405c-8908-e5be1c24ea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.plot_data(restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7101c-5bad-4d07-9fe5-3ead555ae159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying a keep mask and sample slice also works.\n",
    "with zarr.open_group(\"test.zarr\", mode=\"r\") as zf:\n",
    "    sub_restored = flacarray.zarr.read_array(zf, keep=keep, stream_slice=slice(200, 300, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07770e20-fd0c-44ba-9835-6761ef7c8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.plot_data(sub_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8be5f8-7631-495e-9dad-08377e8ca25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
