{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92fc20d7-44b5-4fc6-ae0d-e5863f16102b",
   "metadata": {},
   "source": [
    "# Cook Book\n",
    "\n",
    "This notebook contains some more advanced examples addressing common usage patterns.  Look at the Tutorial first to get a better sense of the big picture of the tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f8ab1-240b-4dd9-90df-b7cfc4d19b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of OpenMP threads to use\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4666df3-4e3f-4e15-a05d-48152eb50e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import h5py\n",
    "from flacarray import FlacArray, demo\n",
    "import flacarray.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c809b72-8e51-4a3d-abc0-a37f78e75d95",
   "metadata": {},
   "source": [
    "## Random Access to Large Arrays\n",
    "\n",
    "Consider a common case where we have a 2D array that represents essentially a \"list\" of timestreams of data.  We might have thousands of timestreams, each with millions of samples.  Now we want to decompress and access a subset of those streams and / or samples.  To reduce memory in this notebook we are using a slightly smaller array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbb6018-8e07-4f89-a532-a619e890c83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array of streams\n",
    "arr = demo.create_fake_data((1000, 100000), dtype=np.float32)\n",
    "# How large is this in memory?\n",
    "print(f\"Input array is {arr.nbytes} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db132c4b-e7e7-4051-b999-7b3bd1d3135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress this with threads\n",
    "start = time.perf_counter()\n",
    "\n",
    "flcarr = FlacArray.from_array(arr, use_threads=True)\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dbb62c-6a08-4910-bd36-d28e59c3a3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compress this without threads\n",
    "start = time.perf_counter()\n",
    "\n",
    "flcarr = FlacArray.from_array(arr, use_threads=False)\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d6760e-b292-4749-b6fa-3a5d0393a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress the whole thing\n",
    "start = time.perf_counter()\n",
    "\n",
    "restored = flcarr.to_array()\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf42e99-d95e-4f78-b45e-5e024bbc3c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompress the whole thing with threads\n",
    "del restored\n",
    "start = time.perf_counter()\n",
    "\n",
    "restored = flcarr.to_array(use_threads=True)\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec67065c-a741-4f87-a0fa-4ff184df012e",
   "metadata": {},
   "source": [
    "### Subset of Samples for All Streams\n",
    "\n",
    "If our 2D array of streams contains co-sampled data, we might mant to examine a slice in time of all streams.  Imagine we wanted to get data near the end of the array for all streams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa9f93d-a3e8-466f-aef3-0aa42b7b61c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_end = 10000\n",
    "start = time.perf_counter()\n",
    "\n",
    "end_arr = flcarr.to_array(stream_slice=slice(-n_end, None, 1))\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8fa3e-6e11-4400-9082-14ac13ae601f",
   "metadata": {},
   "source": [
    "### Subset of Samples for a Few Streams\n",
    "\n",
    "Imagine we want the last 1000 samples of **one** stream in the middle.  We can use a \"keep\" mask combined with a sample slice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8b5c78-a83a-46a0-8a31-f0dc776d9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_end = 10000\n",
    "keep = np.zeros(arr.shape[:-1], dtype=bool)\n",
    "keep[500] = True\n",
    "start = time.perf_counter()\n",
    "\n",
    "sub_arr = flcarr.to_array(keep=keep, stream_slice=slice(-n_end, None, 1))\n",
    "\n",
    "stop = time.perf_counter()\n",
    "print(f\"Elapsed = {stop-start:0.3} seconds\")\n",
    "print(sub_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac64ca0-46ea-4723-81a4-36074c3ba0e7",
   "metadata": {},
   "source": [
    "So, we can see that decompressing a small number of random samples from a multi-GB dataset in memory is very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7d8cc-59ce-4689-93b4-4b97e9945ed9",
   "metadata": {},
   "source": [
    "## Parallel I/O\n",
    "\n",
    "For some use cases, there is no need to keep the full compressed data in memory (in a `FlacArray`).  Instead, a normal numpy array is compressed when writing to a file and decompressed back into a numpy array when reading.  This package has high-level functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b7101c-5bad-4d07-9fe5-3ead555ae159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
