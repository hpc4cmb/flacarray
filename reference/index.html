
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../cookbook/">
      
      
        <link rel="next" href="../dev/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>API Reference - FLACArray</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7e37652d.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../css/print-site.css">
    
      <link rel="stylesheet" href="../css/print-site-material.css">
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="FLACArray" class="md-header__button md-logo" aria-label="FLACArray" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FLACArray
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              API Reference
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="FLACArray" class="md-nav__button md-logo" aria-label="FLACArray" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FLACArray
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../install/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Tutorial
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../cookbook/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cook Book
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#compressed-array-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Compressed Array Representation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compressed Array Representation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FlacArray
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â FlacArray">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.compressed" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;compressed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.dtype" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_leading_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_leading_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_nstreams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_nstreams
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_process_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_process_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_stream_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_stream_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_stream_starts" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_stream_starts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.leading_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;leading_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.mpi_comm" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mpi_comm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.mpi_dist" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mpi_dist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.nstreams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;nstreams
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_gains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_gains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_offsets" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_offsets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_size" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_starts" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_starts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.typestr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;typestr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.__getitem__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__getitem__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.from_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.read_hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read_hdf5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.read_zarr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read_zarr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.to_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;to_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.write_hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write_hdf5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.write_zarr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write_zarr
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#direct-io" class="md-nav__link">
    <span class="md-ellipsis">
      Direct I/O
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Direct I/O">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      HDF5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.hdf5.write_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;write_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.hdf5.read_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;read_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zarr" class="md-nav__link">
    <span class="md-ellipsis">
      Zarr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.zarr.write_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;write_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.zarr.read_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;read_array
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactive-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Interactive Tools
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Interactive Tools">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.demo.create_fake_data" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;create_fake_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.demo.plot_data" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;plot_data
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-level-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Level Tools
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Low-Level Tools">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.compress.array_compress" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_compress
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.decompress.array_decompress" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_decompress
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.decompress.array_decompress_slice" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_decompress_slice
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../dev/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Developer Notes
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="https://github.com/hpc4cmb/flacarray" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Source on GitHub
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../print_page/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    View as Single Page
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#compressed-array-representation" class="md-nav__link">
    <span class="md-ellipsis">
      Compressed Array Representation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Compressed Array Representation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-class"></code>&nbsp;FlacArray
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Â FlacArray">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.compressed" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;compressed
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.dtype" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;dtype
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_leading_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_leading_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_nstreams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_nstreams
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_process_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_process_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_stream_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_stream_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.global_stream_starts" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;global_stream_starts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.leading_shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;leading_shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.mpi_comm" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mpi_comm
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.mpi_dist" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;mpi_dist
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.nstreams" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;nstreams
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.shape" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;shape
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_gains" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_gains
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_nbytes" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_nbytes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_offsets" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_offsets
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_size" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.stream_starts" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;stream_starts
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.typestr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-attribute"></code>&nbsp;typestr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.__getitem__" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;__getitem__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.from_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;from_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.read_hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read_hdf5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.read_zarr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;read_zarr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.to_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;to_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.write_hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write_hdf5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.FlacArray.write_zarr" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-method"></code>&nbsp;write_zarr
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#direct-io" class="md-nav__link">
    <span class="md-ellipsis">
      Direct I/O
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Direct I/O">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hdf5" class="md-nav__link">
    <span class="md-ellipsis">
      HDF5
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.hdf5.write_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;write_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.hdf5.read_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;read_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#zarr" class="md-nav__link">
    <span class="md-ellipsis">
      Zarr
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.zarr.write_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;write_array
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.zarr.read_array" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;read_array
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#interactive-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Interactive Tools
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Interactive Tools">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.demo.create_fake_data" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;create_fake_data
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.demo.plot_data" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;plot_data
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#low-level-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Low-Level Tools
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Low-Level Tools">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#flacarray.compress.array_compress" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_compress
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.decompress.array_decompress" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_decompress
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#flacarray.decompress.array_decompress_slice" class="md-nav__link">
    <span class="md-ellipsis">
      <code class="doc-symbol doc-symbol-toc doc-symbol-function"></code>&nbsp;array_decompress_slice
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="api-reference">API Reference</h1>
<p>The <code>flacarray</code> package consists of a primary class (<code>FlacArray</code>) plus a
variety of helper functions.</p>
<h2 id="compressed-array-representation">Compressed Array Representation</h2>
<p>The <code>FlacArray</code> class stores a compressed representation of an N dimensional
array where the last dimension consists of "streams" of numbers to be
compressed.</p>


<div class="doc doc-object doc-class">



<h3 id="flacarray.FlacArray" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-class"></code>            <code>flacarray.FlacArray</code>


</h3>


    <div class="doc doc-contents first">


        <p>FLAC compressed array representation.</p>
<p>This class holds a compressed representation of an N-dimensional array.  The final
(fastest changing) dimension is the axis along which the data is compressed.  Each
of the vectors in this last dimension is called a "stream" here.  The leading
dimensions of the original matrix form an array of these streams.</p>
<p>Internally, the data is stored as a contiguous concatenation of the bytes from
these compressed streams.  A separate array contains the starting byte of each
stream in the overall bytes array.  The shape of the starting array corresponds
to the shape of the leading, un-compressed dimensions of the original array.</p>
<p>If the input data is 32bit or 64bit integers, each stream in the array is
compressed directly with FLAC.</p>
<p>If the input data is 32bit or 64bit floating point numbers, then you <strong>must</strong>
specify exactly one of either quanta or precision when calling <code>from_array()</code>.  For
floating point data, the mean of each stream is computed and rounded to the nearest
whole quanta.  This "offset" per stream is recorded and subtracted from the
stream.  The offset-subtracted stream data is then rescaled and truncated to
integers (int32 or int64 depending on the bit width of the input array).  If
<code>quanta</code> is specified, the data is rescaled by 1 / quanta.  The quanta may either
be a scalar applied to all streams, or an array of values, one per stream.  If
instead the precision (integer number of decimal places) is specified, this is
converted to a quanta by dividing the stream RMS by <code>10^{precision}</code>.  Similar to
quanta, the precision may be specified as a single value for all streams, or as an
array of values, one per stream.</p>
<p>If you choose a quanta value that is close to machine epsilon (e.g. 1e-7 for 32bit
or 1e-16 for 64bit), then the compression amount will be negligible but the results
nearly lossless. Compression of floating point data should not be done blindly and
you should consider the underlying precision of the data you are working with in
order to achieve the best compression possible.</p>
<p>The following rules summarize the data conversion that is performed depending on
the input type:</p>
<ul>
<li>
<p>int32:  No conversion.  Compressed to single channel FLAC bytestream.</p>
</li>
<li>
<p>int64:  No conversion.  Compressed to 2-channel (stereo) FLAC bytestream.</p>
</li>
<li>
<p>float32:  Subtract the offset per stream and scale data based on the quanta value
    or precision (see above).  Then round to nearest 32bit integer.</p>
</li>
<li>
<p>float64:  Subtract the offset per stream and scale data based on the quanta value
    or precision (see above).  Then round to nearest 64bit integer.</p>
</li>
</ul>
<p>After conversion to integers, each stream's data is separately compressed into a
sequence of FLAC bytes, which is appended to the bytestream.  The offset in bytes
for each stream is recorded.</p>
<p>A FlacArray is only constructed directly when making a copy.  Use the class methods
to create FlacArrays from numpy arrays or on-disk representations.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>other</code>
            </td>
            <td>
                  <code><a class="autorefs autorefs-internal" title="            flacarray.FlacArray (flacarray.array.FlacArray)" href="#flacarray.FlacArray">FlacArray</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Construct a copy of the input FlacArray.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>







              <details class="quote">
                <summary>Source code in <code>flacarray/array.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">FlacArray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;FLAC compressed array representation.</span>

<span class="sd">    This class holds a compressed representation of an N-dimensional array.  The final</span>
<span class="sd">    (fastest changing) dimension is the axis along which the data is compressed.  Each</span>
<span class="sd">    of the vectors in this last dimension is called a &quot;stream&quot; here.  The leading</span>
<span class="sd">    dimensions of the original matrix form an array of these streams.</span>

<span class="sd">    Internally, the data is stored as a contiguous concatenation of the bytes from</span>
<span class="sd">    these compressed streams.  A separate array contains the starting byte of each</span>
<span class="sd">    stream in the overall bytes array.  The shape of the starting array corresponds</span>
<span class="sd">    to the shape of the leading, un-compressed dimensions of the original array.</span>

<span class="sd">    If the input data is 32bit or 64bit integers, each stream in the array is</span>
<span class="sd">    compressed directly with FLAC.</span>

<span class="sd">    If the input data is 32bit or 64bit floating point numbers, then you **must**</span>
<span class="sd">    specify exactly one of either quanta or precision when calling `from_array()`.  For</span>
<span class="sd">    floating point data, the mean of each stream is computed and rounded to the nearest</span>
<span class="sd">    whole quanta.  This &quot;offset&quot; per stream is recorded and subtracted from the</span>
<span class="sd">    stream.  The offset-subtracted stream data is then rescaled and truncated to</span>
<span class="sd">    integers (int32 or int64 depending on the bit width of the input array).  If</span>
<span class="sd">    `quanta` is specified, the data is rescaled by 1 / quanta.  The quanta may either</span>
<span class="sd">    be a scalar applied to all streams, or an array of values, one per stream.  If</span>
<span class="sd">    instead the precision (integer number of decimal places) is specified, this is</span>
<span class="sd">    converted to a quanta by dividing the stream RMS by `10^{precision}`.  Similar to</span>
<span class="sd">    quanta, the precision may be specified as a single value for all streams, or as an</span>
<span class="sd">    array of values, one per stream.</span>

<span class="sd">    If you choose a quanta value that is close to machine epsilon (e.g. 1e-7 for 32bit</span>
<span class="sd">    or 1e-16 for 64bit), then the compression amount will be negligible but the results</span>
<span class="sd">    nearly lossless. Compression of floating point data should not be done blindly and</span>
<span class="sd">    you should consider the underlying precision of the data you are working with in</span>
<span class="sd">    order to achieve the best compression possible.</span>

<span class="sd">    The following rules summarize the data conversion that is performed depending on</span>
<span class="sd">    the input type:</span>

<span class="sd">    * int32:  No conversion.  Compressed to single channel FLAC bytestream.</span>

<span class="sd">    * int64:  No conversion.  Compressed to 2-channel (stereo) FLAC bytestream.</span>

<span class="sd">    * float32:  Subtract the offset per stream and scale data based on the quanta value</span>
<span class="sd">        or precision (see above).  Then round to nearest 32bit integer.</span>

<span class="sd">    * float64:  Subtract the offset per stream and scale data based on the quanta value</span>
<span class="sd">        or precision (see above).  Then round to nearest 64bit integer.</span>

<span class="sd">    After conversion to integers, each stream&#39;s data is separately compressed into a</span>
<span class="sd">    sequence of FLAC bytes, which is appended to the bytestream.  The offset in bytes</span>
<span class="sd">    for each stream is recorded.</span>

<span class="sd">    A FlacArray is only constructed directly when making a copy.  Use the class methods</span>
<span class="sd">    to create FlacArrays from numpy arrays or on-disk representations.</span>

<span class="sd">    Args:</span>
<span class="sd">        other (FlacArray):  Construct a copy of the input FlacArray.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">other</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">compressed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">other</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We are copying an existing object, make sure we have an</span>
            <span class="c1"># independent copy.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_global_shape</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_compressed</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">other</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">)</span>
            <span class="c1"># MPI communicators can be limited in number and expensive to create.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span> <span class="o">=</span> <span class="n">other</span><span class="o">.</span><span class="n">_mpi_comm</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># This form of constructor is used in the class methods where we</span>
            <span class="c1"># have already created these arrays for use by this instance.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">=</span> <span class="n">shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span> <span class="o">=</span> <span class="n">global_shape</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span> <span class="o">=</span> <span class="n">compressed</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span> <span class="o">=</span> <span class="n">stream_starts</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span> <span class="o">=</span> <span class="n">stream_nbytes</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span> <span class="o">=</span> <span class="n">stream_offsets</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span> <span class="o">=</span> <span class="n">stream_gains</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span> <span class="o">=</span> <span class="n">mpi_comm</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span> <span class="o">=</span> <span class="n">mpi_dist</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="c1"># The input `_shape` parameter is the original shape when the instance</span>
        <span class="c1"># was created from an array or read from disk.  In the case of a single</span>
        <span class="c1"># stream, this tracks the user intentions about whether to flatten the</span>
        <span class="c1"># leading dimension.  We also track the &quot;local shape&quot;, with is the same,</span>
        <span class="c1"># but which always keeps the leading dimension.</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_local_nbytes</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="o">.</span><span class="n">nbytes</span>
        <span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">global_bytes</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_nbytes</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># For reference, record the type string of the original data.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_typestr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype_str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
        <span class="c1"># Track whether we have 32bit or 64bit data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">float64</span>
        <span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">_dtype_str</span><span class="p">(</span><span class="n">dt</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">dt</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;float64&quot;</span>
        <span class="k">elif</span> <span class="n">dt</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;float32&quot;</span>
        <span class="k">elif</span> <span class="n">dt</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;int64&quot;</span>
        <span class="k">elif</span> <span class="n">dt</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
            <span class="k">return</span> <span class="s2">&quot;int32&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Unsupported dtype &#39;</span><span class="si">{</span><span class="n">dt</span><span class="si">}</span><span class="s2">&#39;&quot;</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="c1"># Shapes of decompressed array</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The shape of the local, uncompressed array.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The global shape of array across any MPI communicator.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">leading_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The local shape of leading uncompressed dimensions.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_leading_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The global shape of leading uncompressed dimensions across all processes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stream_size</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The uncompressed length of each stream.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span>

    <span class="c1"># Properties of the compressed data</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The total number of bytes used by compressed data on the local process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_nbytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The sum of total bytes used by compressed data across all processes.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_process_nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The bytes used by compressed data on each process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_bytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">nstreams</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The number of local streams (product of entries of `leading_shape`)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_nstreams</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_nstreams</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Number of global streams (product of entries of `global_leading_shape`)&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_nstreams</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">compressed</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The concatenated raw bytes of all streams on the local process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stream_starts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The array of starting bytes for each stream on the local process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stream_nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The array of nbytes for each stream on the local process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_stream_starts</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The array of starting bytes within the global compressed data.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">global_stream_nbytes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The array of nbytes within the global compressed data.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_nbytes</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stream_offsets</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The value subtracted from each stream during conversion to int32.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">stream_gains</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The gain factor for each stream during conversion to int32.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mpi_comm</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The MPI communicator over which the array is distributed.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">mpi_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The range of the leading dimension assigned to each MPI process.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The dtype of the uncompressed array.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span>

    <span class="nd">@property</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">typestr</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A string representation of the original data type.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_typestr</span>

    <span class="c1"># __getitem__ slicing / decompression on the fly and associated</span>
    <span class="c1"># helper functions.</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_slice_nelem</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">slc</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get the number of elements in a slice.&quot;&quot;&quot;</span>
        <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="n">slc</span><span class="o">.</span><span class="n">indices</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
        <span class="n">nslc</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="o">//</span> <span class="n">step</span>
        <span class="k">if</span> <span class="n">nslc</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">nslc</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="n">nslc</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_keep_view</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Convert leading-shape key to bool array.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;keep_view </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> does not match leading &quot;</span>
            <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;dimensions </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="n">view</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">bool</span><span class="p">)</span>
        <span class="n">view</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">view</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_full_key</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process the incoming key so that it covers all dimensions.</span>

<span class="sd">        Args:</span>
<span class="sd">            key (tuple):  The input key consisting of an integer or a tuple</span>
<span class="sd">                of slices and / or integers.</span>

<span class="sd">        Result:</span>
<span class="sd">            (tuple):  The full key.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">ndim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">)</span>
        <span class="n">full_key</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span><span class="p">:</span>
            <span class="c1"># Our array is a single stream with flattened shape.  The user</span>
            <span class="c1"># supplied key should only contain the sample axis.</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="c1"># It better have length == 1...</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Slice key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2"> is not valid for single, &quot;</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;flattened stream.&quot;</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="n">full_key</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">key</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># Single element, compress sample dimension</span>
                <span class="n">full_key</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">key</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
                <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axkey</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">key</span><span class="p">):</span>
                    <span class="n">full_key</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axkey</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">full_key</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_key</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">ndim</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Invalid slice key </span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">, too many dimensions&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

        <span class="c1"># Fill in remaining dimensions</span>
        <span class="n">filled</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_key</span><span class="p">)</span>
        <span class="n">full_key</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">)</span> <span class="o">-</span> <span class="n">filled</span><span class="p">)])</span>
        <span class="k">return</span> <span class="n">full_key</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_leading_axes</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process the leading axes.</span>

<span class="sd">        Args:</span>
<span class="sd">            full_key (tuple):  The full-rank selection key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (tuple):  The (leading_shape, keep array).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="n">keep_slice</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span><span class="p">:</span>
            <span class="c1"># Our array is a single stream with flattened shape.</span>
            <span class="n">keep_slice</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axkey</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">full_key</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axkey</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
                    <span class="c1"># Some kind of slice, do not compress this dimension.</span>
                    <span class="n">nslc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_slice_nelem</span><span class="p">(</span><span class="n">axkey</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">])</span>
                    <span class="n">leading_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nslc</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># Check for validity</span>
                    <span class="k">if</span> <span class="n">axkey</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">axkey</span> <span class="o">&gt;=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_local_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]:</span>
                        <span class="c1"># Insert a zero-length dimension so that a zero-length</span>
                        <span class="c1"># array is returned in the calling code.</span>
                        <span class="n">leading_shape</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># This dimension is a single element and will be</span>
                        <span class="c1"># compressed.</span>
                        <span class="k">pass</span>
                <span class="n">keep_slice</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axkey</span><span class="p">)</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">leading_shape</span><span class="p">)</span>
        <span class="n">keep_slice</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">keep_slice</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">keep_slice</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">keep</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_keep_view</span><span class="p">(</span><span class="n">keep_slice</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">leading_shape</span><span class="p">,</span> <span class="n">keep</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_sample_axis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">full_key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Process any slicing of the stream axis.</span>

<span class="sd">        Args:</span>
<span class="sd">            full_key (tuple):  The full-rank selection key.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (tuple):  The (first, last, sample_shape).</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sample_key</span> <span class="o">=</span> <span class="n">full_key</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">sample_key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,))</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="nb">slice</span><span class="p">):</span>
            <span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="n">sample_key</span><span class="o">.</span><span class="n">indices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">step</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Only stride==1 supported on stream slices&quot;</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">stop</span> <span class="o">-</span> <span class="n">start</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="c1"># No samples</span>
                <span class="k">return</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="p">(</span><span class="n">stop</span><span class="o">-</span><span class="n">start</span><span class="p">,))</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">integer</span><span class="p">)):</span>
            <span class="c1"># Just a scalar</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">sample_key</span><span class="p">,</span> <span class="n">sample_key</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;Stream dimension supports contiguous slices or single indices.&quot;</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_key</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decompress a slice of data on the fly.</span>

<span class="sd">        Args:</span>
<span class="sd">            raw_key (tuple):  A tuple of slices or integers.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (array):  The decompressed array slice.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the key for all dimensions</span>
        <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_full_key</span><span class="p">(</span><span class="n">raw_key</span><span class="p">)</span>

        <span class="c1"># Compute the output leading shape and keep array</span>
        <span class="n">leading_shape</span><span class="p">,</span> <span class="n">keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_leading_axes</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="c1"># Compute sample axis slice</span>
        <span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">sample_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sample_axis</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

        <span class="n">full_shape</span> <span class="o">=</span> <span class="n">leading_shape</span> <span class="o">+</span> <span class="n">sample_shape</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">n_total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># At least one dimension was zero, return empty array</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">full_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">arr</span><span class="p">,</span> <span class="n">strm_indices</span> <span class="o">=</span> <span class="n">array_decompress_slice</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
                <span class="n">stream_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
                <span class="n">stream_gains</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
                <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
                <span class="n">first_stream_sample</span><span class="o">=</span><span class="n">first</span><span class="p">,</span>
                <span class="n">last_stream_sample</span><span class="o">=</span><span class="n">last</span><span class="p">,</span>
                <span class="n">is_int64</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__delitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot delete individual streams&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__setitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot modify individual byte streams&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">mpistr</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">rank</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="o">.</span><span class="n">rank</span>
            <span class="n">mpistr</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot; | Rank </span><span class="si">{</span><span class="n">rank</span><span class="si">:</span><span class="s2">04d</span><span class="si">}</span><span class="s2"> &quot;</span>
            <span class="n">mpistr</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">-&quot;</span>
            <span class="n">mpistr</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> |&quot;</span>
        <span class="n">rep</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;&lt;FlacArray</span><span class="si">{</span><span class="n">mpistr</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_typestr</span><span class="si">}</span><span class="s2"> &quot;</span>
        <span class="n">rep</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;shape=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2"> bytes=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_local_nbytes</span><span class="si">}</span><span class="s2">&gt;&quot;</span>
        <span class="k">return</span> <span class="n">rep</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__eq__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_shape</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">_shape</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;other shape </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">_dtype</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;other dtype </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_dtype</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span> <span class="o">!=</span> <span class="n">other</span><span class="o">.</span><span class="n">_global_shape</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;other global_shape </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_global_shape</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_global_shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;other starts </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_starts</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_compressed</span><span class="p">):</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;other compressed </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_compressed</span><span class="si">}</span><span class="s2"> != </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_offsets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;other stream_offsets not None, self is None&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_offsets</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;other stream_offsets is None, self is not None&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">):</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;other stream_offsets </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="si">}</span><span class="s2"> != &quot;</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_gains</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;other stream_gains not None, self is None&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_gains</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="s2">&quot;other stream_offsets is None, self is not None&quot;</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span> <span class="n">other</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">):</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;other stream_gains </span><span class="si">{</span><span class="n">other</span><span class="o">.</span><span class="n">_stream_gains</span><span class="si">}</span><span class="s2"> != &quot;</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                    <span class="k">return</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">to_array</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Decompress local data into a numpy array.</span>

<span class="sd">        This uses the compressed representation to reconstruct a normal numpy</span>
<span class="sd">        array.  The returned data type will be either int32, int64, float32, or</span>
<span class="sd">        float64 depending on the original data type.</span>

<span class="sd">        If `stream_slice` is specified, the returned array will have only that</span>
<span class="sd">        range of samples in the final dimension.</span>

<span class="sd">        If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">        as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">        indicate that the stream should be kept.</span>

<span class="sd">        If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">        the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">        streams corresponding to True values in the `keep` mask.</span>

<span class="sd">        If `keep_indices` is True and `keep` is specified, then a tuple of two values</span>
<span class="sd">        is returned.  The first is the array of decompressed streams.  The second is</span>
<span class="sd">        a list of tuples, each of which specifies the indices of the stream in the</span>
<span class="sd">        original array.</span>

<span class="sd">        Args:</span>
<span class="sd">            keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">            stream_slice (slice):  A python slice with step size of one, indicating</span>
<span class="sd">                the sample range to extract from each stream.</span>
<span class="sd">            keep_indices (bool):  If True, also return the original indices of the</span>
<span class="sd">                streams.</span>
<span class="sd">            use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">                This is only beneficial for large arrays.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">first_samp</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">last_samp</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">stream_slice</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">step</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                    <span class="s2">&quot;Only stream slices with a step size of 1 are supported&quot;</span>
                <span class="p">)</span>
            <span class="n">first_samp</span> <span class="o">=</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">start</span>
            <span class="n">last_samp</span> <span class="o">=</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">stop</span>

        <span class="n">arr</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">array_decompress_slice</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
            <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
            <span class="n">first_stream_sample</span><span class="o">=</span><span class="n">first_samp</span><span class="p">,</span>
            <span class="n">last_stream_sample</span><span class="o">=</span><span class="n">last_samp</span><span class="p">,</span>
            <span class="n">is_int64</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">,</span>
            <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
            <span class="n">no_flatten</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">keep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keep_indices</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">arr</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">from_array</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from a numpy ndarray.</span>

<span class="sd">        Args:</span>
<span class="sd">            arr (numpy.ndarray):  The input array data.</span>
<span class="sd">            level (int):  Compression level (0-8).</span>
<span class="sd">            quanta (float, array):  For floating point data, the floating point</span>
<span class="sd">                increment of each 32bit integer value.  Optionally an iterable of</span>
<span class="sd">                increments, one per stream.</span>
<span class="sd">            precision (int, array):  Number of significant digits to retain in</span>
<span class="sd">                float-to-int conversion.  Alternative to `quanta`.  Optionally an</span>
<span class="sd">                iterable of values, one per stream.</span>
<span class="sd">            mpi_comm (MPI.Comm):  If specified, the input array is assumed to be</span>
<span class="sd">                distributed across the communicator at the leading dimension.  The</span>
<span class="sd">                local piece of the array is passed in on each process.</span>
<span class="sd">            use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">                This is only beneficial for large arrays.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Get the global shape of the array</span>
        <span class="n">global_props</span> <span class="o">=</span> <span class="n">global_array_properties</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">)</span>
        <span class="n">global_shape</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span>
        <span class="n">mpi_dist</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;dist&quot;</span><span class="p">]</span>

        <span class="c1"># Compress our local piece of the array</span>
        <span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">gains</span> <span class="o">=</span> <span class="n">array_compress</span><span class="p">(</span>
            <span class="n">arr</span><span class="p">,</span>
            <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
            <span class="n">quanta</span><span class="o">=</span><span class="n">quanta</span><span class="p">,</span>
            <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
            <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
            <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">stream_starts</span><span class="o">=</span><span class="n">starts</span><span class="p">,</span>
            <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="o">=</span><span class="n">gains</span><span class="p">,</span>
            <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hgrp</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write data to an HDF5 Group.</span>

<span class="sd">        The internal object properties are written to an open HDF5 group.  If you</span>
<span class="sd">        wish to use MPI I/O to write data to the group, then you must be using an MPI</span>
<span class="sd">        enabled h5py and you should pass in a valid handle to the group on all</span>
<span class="sd">        processes.</span>

<span class="sd">        If the `FlacArray` is distributed over an MPI communicator, but the h5py</span>
<span class="sd">        implementation does not support MPI I/O, then all data will be communicated</span>
<span class="sd">        to the rank zero process for writing.  In this case, the `hgrp` argument should</span>
<span class="sd">        be None except on the root process.</span>

<span class="sd">        Args:</span>
<span class="sd">            hgrp (h5py.Group):  The open Group for writing.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">:</span>
            <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="n">hdf5_write_compressed</span><span class="p">(</span>
            <span class="n">hgrp</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
            <span class="n">n_channels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">read_hdf5</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">hgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from an HDF5 Group.</span>

<span class="sd">        This function loads all information about the array from an HDF5 group.  If</span>
<span class="sd">        `mpi_comm` is specified, the created array is distributed over that</span>
<span class="sd">        communicator.  If you also wish to use MPI I/O to read data from the group,</span>
<span class="sd">        then you must be using an MPI-enabled h5py and you should pass in a valid</span>
<span class="sd">        handle to the group on all processes.</span>

<span class="sd">        If `mpi_dist` is specified, it should be an iterable with the number of leading</span>
<span class="sd">        dimension elements assigned to each process.  If None, the leading dimension</span>
<span class="sd">        will be distributed uniformly.</span>

<span class="sd">        If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">        as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">        indicate that the stream should be kept.</span>

<span class="sd">        If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">        the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">        streams corresponding to True values in the `keep` mask.</span>

<span class="sd">        Args:</span>
<span class="sd">            hgrp (h5py.Group):  The open Group for reading.</span>
<span class="sd">            keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">            mpi_comm (MPI.Comm):  If specified, the communicator over which to</span>
<span class="sd">                distribute the leading dimension.</span>
<span class="sd">            mpi_dist (array):  If specified, assign blocks of these sizes to processes</span>
<span class="sd">                when distributing the leading dimension.</span>
<span class="sd">            no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">                dimension of (1,) in the result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span>
            <span class="n">local_shape</span><span class="p">,</span>
            <span class="n">global_shape</span><span class="p">,</span>
            <span class="n">compressed</span><span class="p">,</span>
            <span class="n">n_channels</span><span class="p">,</span>
            <span class="n">stream_starts</span><span class="p">,</span>
            <span class="n">stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="p">,</span>
            <span class="n">keep_indices</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">hdf5_read_compressed</span><span class="p">(</span>
            <span class="n">hgrp</span><span class="p">,</span>
            <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
            <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">dt</span> <span class="o">=</span> <span class="n">compressed_dtype</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="p">,</span> <span class="n">stream_gains</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">local_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">local_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_flatten</span><span class="p">:</span>
            <span class="c1"># Flatten</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">local_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">local_shape</span>

        <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
            <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span>
            <span class="n">stream_starts</span><span class="o">=</span><span class="n">stream_starts</span><span class="p">,</span>
            <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="o">=</span><span class="n">stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="o">=</span><span class="n">stream_gains</span><span class="p">,</span>
            <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">write_zarr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zgrp</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Write data to an Zarr Group.</span>

<span class="sd">        The internal object properties are written to an open zarr group.</span>

<span class="sd">        If the `FlacArray` is distributed over an MPI communicator, then all data will</span>
<span class="sd">        be communicated to the rank zero process for writing.  In this case, the `zgrp`</span>
<span class="sd">        argument should be None except on the root process.</span>

<span class="sd">        Args:</span>
<span class="sd">            zgrp (zarr.Group):  The open Group for writing.</span>

<span class="sd">        Returns:</span>
<span class="sd">            None</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">:</span>
            <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">zarr_write_compressed</span><span class="p">(</span>
            <span class="n">zgrp</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
            <span class="n">n_channels</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_nbytes</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">read_zarr</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">zgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from a Zarr Group.</span>

<span class="sd">        This function loads all information about the array from a zarr group.  If</span>
<span class="sd">        `mpi_comm` is specified, the created array is distributed over that</span>
<span class="sd">        communicator.</span>

<span class="sd">        If `mpi_dist` is specified, it should be an iterable with the number of leading</span>
<span class="sd">        dimension elements assigned to each process.  If None, the leading dimension</span>
<span class="sd">        will be distributed uniformly.</span>

<span class="sd">        If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">        as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">        indicate that the stream should be kept.</span>

<span class="sd">        If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">        the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">        streams corresponding to True values in the `keep` mask.</span>

<span class="sd">        Args:</span>
<span class="sd">            zgrp (zarr.Group):  The open Group for reading.</span>
<span class="sd">            keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">            mpi_comm (MPI.Comm):  If specified, the communicator over which to</span>
<span class="sd">                distribute the leading dimension.</span>
<span class="sd">            mpi_dist (array):  If specified, assign blocks of these sizes to processes</span>
<span class="sd">                when distributing the leading dimension.</span>
<span class="sd">            no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">                dimension of (1,) in the result.</span>

<span class="sd">        Returns:</span>
<span class="sd">            (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="p">(</span>
            <span class="n">local_shape</span><span class="p">,</span>
            <span class="n">global_shape</span><span class="p">,</span>
            <span class="n">compressed</span><span class="p">,</span>
            <span class="n">n_channels</span><span class="p">,</span>
            <span class="n">stream_starts</span><span class="p">,</span>
            <span class="n">stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="p">,</span>
            <span class="n">keep_indices</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">zarr_read_compressed</span><span class="p">(</span>
            <span class="n">zgrp</span><span class="p">,</span>
            <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
            <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">dt</span> <span class="o">=</span> <span class="n">compressed_dtype</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="p">,</span> <span class="n">stream_gains</span><span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">local_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">local_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_flatten</span><span class="p">:</span>
            <span class="c1"># Flatten</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">local_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">shape</span> <span class="o">=</span> <span class="n">local_shape</span>

        <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
            <span class="kc">None</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
            <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
            <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span>
            <span class="n">stream_starts</span><span class="o">=</span><span class="n">stream_starts</span><span class="p">,</span>
            <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="o">=</span><span class="n">stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="o">=</span><span class="n">stream_gains</span><span class="p">,</span>
            <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
            <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.compressed" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">compressed</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The concatenated raw bytes of all streams on the local process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.dtype" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">dtype</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The dtype of the uncompressed array.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_leading_shape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_leading_shape</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The global shape of leading uncompressed dimensions across all processes.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_nbytes" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_nbytes</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The sum of total bytes used by compressed data across all processes.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_nstreams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_nstreams</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Number of global streams (product of entries of <code>global_leading_shape</code>)</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_process_nbytes" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_process_nbytes</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The bytes used by compressed data on each process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_shape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_shape</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The global shape of array across any MPI communicator.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_stream_nbytes" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_stream_nbytes</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The array of nbytes within the global compressed data.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.global_stream_starts" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">global_stream_starts</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The array of starting bytes within the global compressed data.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.leading_shape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">leading_shape</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The local shape of leading uncompressed dimensions.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.mpi_comm" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">mpi_comm</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The MPI communicator over which the array is distributed.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.mpi_dist" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">mpi_dist</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The range of the leading dimension assigned to each MPI process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.nbytes" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">nbytes</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The total number of bytes used by compressed data on the local process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.nstreams" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">nstreams</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The number of local streams (product of entries of <code>leading_shape</code>)</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.shape" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">shape</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The shape of the local, uncompressed array.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.stream_gains" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">stream_gains</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The gain factor for each stream during conversion to int32.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.stream_nbytes" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">stream_nbytes</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The array of nbytes for each stream on the local process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.stream_offsets" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">stream_offsets</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The value subtracted from each stream during conversion to int32.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.stream_size" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">stream_size</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The uncompressed length of each stream.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.stream_starts" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">stream_starts</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>The array of starting bytes for each stream on the local process.</p>

    </div>

</div>

<div class="doc doc-object doc-attribute">



<h4 id="flacarray.FlacArray.typestr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-attribute"></code>            <code class="highlight language-python"><span class="n">typestr</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>A string representation of the original data type.</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.__getitem__" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="fm">__getitem__</span><span class="p">(</span><span class="n">raw_key</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Decompress a slice of data on the fly.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>raw_key</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A tuple of slices or integers.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The decompressed array slice.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">raw_key</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decompress a slice of data on the fly.</span>

<span class="sd">    Args:</span>
<span class="sd">        raw_key (tuple):  A tuple of slices or integers.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (array):  The decompressed array slice.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get the key for all dimensions</span>
    <span class="n">key</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_full_key</span><span class="p">(</span><span class="n">raw_key</span><span class="p">)</span>

    <span class="c1"># Compute the output leading shape and keep array</span>
    <span class="n">leading_shape</span><span class="p">,</span> <span class="n">keep</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_leading_axes</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="c1"># Compute sample axis slice</span>
    <span class="n">first</span><span class="p">,</span> <span class="n">last</span><span class="p">,</span> <span class="n">sample_shape</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_sample_axis</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>

    <span class="n">full_shape</span> <span class="o">=</span> <span class="n">leading_shape</span> <span class="o">+</span> <span class="n">sample_shape</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">n_total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">n_total</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="c1"># At least one dimension was zero, return empty array</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">full_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">arr</span><span class="p">,</span> <span class="n">strm_indices</span> <span class="o">=</span> <span class="n">array_decompress_slice</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
            <span class="n">stream_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
            <span class="n">stream_gains</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
            <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
            <span class="n">first_stream_sample</span><span class="o">=</span><span class="n">first</span><span class="p">,</span>
            <span class="n">last_stream_sample</span><span class="o">=</span><span class="n">last</span><span class="p">,</span>
            <span class="n">is_int64</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">full_shape</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.from_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">from_array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Construct a FlacArray from a numpy ndarray.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>arr</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input array data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compression level (0-8).</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quanta</code>
            </td>
            <td>
                  <code>(<span title="float">float</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For floating point data, the floating point
increment of each 32bit integer value.  Optionally an iterable of
increments, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code>(<span title="int">int</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of significant digits to retain in
float-to-int conversion.  Alternative to <code>quanta</code>.  Optionally an
iterable of values, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, the input array is assumed to be
distributed across the communicator at the leading dimension.  The
local piece of the array is passed in on each process.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="            flacarray.FlacArray (flacarray.array.FlacArray)" href="#flacarray.FlacArray">FlacArray</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A newly constructed FlacArray.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">from_array</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from a numpy ndarray.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (numpy.ndarray):  The input array data.</span>
<span class="sd">        level (int):  Compression level (0-8).</span>
<span class="sd">        quanta (float, array):  For floating point data, the floating point</span>
<span class="sd">            increment of each 32bit integer value.  Optionally an iterable of</span>
<span class="sd">            increments, one per stream.</span>
<span class="sd">        precision (int, array):  Number of significant digits to retain in</span>
<span class="sd">            float-to-int conversion.  Alternative to `quanta`.  Optionally an</span>
<span class="sd">            iterable of values, one per stream.</span>
<span class="sd">        mpi_comm (MPI.Comm):  If specified, the input array is assumed to be</span>
<span class="sd">            distributed across the communicator at the leading dimension.  The</span>
<span class="sd">            local piece of the array is passed in on each process.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Get the global shape of the array</span>
    <span class="n">global_props</span> <span class="o">=</span> <span class="n">global_array_properties</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">)</span>
    <span class="n">global_shape</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span>
    <span class="n">mpi_dist</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;dist&quot;</span><span class="p">]</span>

    <span class="c1"># Compress our local piece of the array</span>
    <span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">gains</span> <span class="o">=</span> <span class="n">array_compress</span><span class="p">(</span>
        <span class="n">arr</span><span class="p">,</span>
        <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
        <span class="n">quanta</span><span class="o">=</span><span class="n">quanta</span><span class="p">,</span>
        <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
        <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="o">=</span><span class="n">starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="n">offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="n">gains</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.read_hdf5" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">read_hdf5</span><span class="p">(</span><span class="n">hgrp</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Construct a FlacArray from an HDF5 Group.</p>
<p>This function loads all information about the array from an HDF5 group.  If
<code>mpi_comm</code> is specified, the created array is distributed over that
communicator.  If you also wish to use MPI I/O to read data from the group,
then you must be using an MPI-enabled h5py and you should pass in a valid
handle to the group on all processes.</p>
<p>If <code>mpi_dist</code> is specified, it should be an iterable with the number of leading
dimension elements assigned to each process.  If None, the leading dimension
will be distributed uniformly.</p>
<p>If <code>keep</code> is specified, this should be a boolean array with the same shape
as the leading dimensions of the original array.  True values in this array
indicate that the stream should be kept.</p>
<p>If <code>keep</code> is specified, the returned array WILL NOT have the same shape as
the original.  Instead it will be a 2D array of decompressed streams- the
streams corresponding to True values in the <code>keep</code> mask.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hgrp</code>
            </td>
            <td>
                  <code><span title="h5py.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The open Group for reading.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, the communicator over which to
distribute the leading dimension.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_dist</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, assign blocks of these sizes to processes
when distributing the leading dimension.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>no_flatten</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, for single-stream arrays, leave the leading
dimension of (1,) in the result.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="            flacarray.FlacArray (flacarray.array.FlacArray)" href="#flacarray.FlacArray">FlacArray</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A newly constructed FlacArray.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">read_hdf5</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">hgrp</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from an HDF5 Group.</span>

<span class="sd">    This function loads all information about the array from an HDF5 group.  If</span>
<span class="sd">    `mpi_comm` is specified, the created array is distributed over that</span>
<span class="sd">    communicator.  If you also wish to use MPI I/O to read data from the group,</span>
<span class="sd">    then you must be using an MPI-enabled h5py and you should pass in a valid</span>
<span class="sd">    handle to the group on all processes.</span>

<span class="sd">    If `mpi_dist` is specified, it should be an iterable with the number of leading</span>
<span class="sd">    dimension elements assigned to each process.  If None, the leading dimension</span>
<span class="sd">    will be distributed uniformly.</span>

<span class="sd">    If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">    as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">    indicate that the stream should be kept.</span>

<span class="sd">    If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">    the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">    streams corresponding to True values in the `keep` mask.</span>

<span class="sd">    Args:</span>
<span class="sd">        hgrp (h5py.Group):  The open Group for reading.</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        mpi_comm (MPI.Comm):  If specified, the communicator over which to</span>
<span class="sd">            distribute the leading dimension.</span>
<span class="sd">        mpi_dist (array):  If specified, assign blocks of these sizes to processes</span>
<span class="sd">            when distributing the leading dimension.</span>
<span class="sd">        no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">            dimension of (1,) in the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">local_shape</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="p">,</span>
        <span class="n">compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="p">,</span>
        <span class="n">keep_indices</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">hdf5_read_compressed</span><span class="p">(</span>
        <span class="n">hgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dt</span> <span class="o">=</span> <span class="n">compressed_dtype</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="p">,</span> <span class="n">stream_gains</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">local_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">local_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_flatten</span><span class="p">:</span>
        <span class="c1"># Flatten</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">local_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">local_shape</span>

    <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
        <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="o">=</span><span class="n">stream_starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="n">stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="n">stream_gains</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.read_zarr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">read_zarr</span><span class="p">(</span><span class="n">zgrp</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-classmethod"><code>classmethod</code></small>
  </span>

</h4>


    <div class="doc doc-contents ">

        <p>Construct a FlacArray from a Zarr Group.</p>
<p>This function loads all information about the array from a zarr group.  If
<code>mpi_comm</code> is specified, the created array is distributed over that
communicator.</p>
<p>If <code>mpi_dist</code> is specified, it should be an iterable with the number of leading
dimension elements assigned to each process.  If None, the leading dimension
will be distributed uniformly.</p>
<p>If <code>keep</code> is specified, this should be a boolean array with the same shape
as the leading dimensions of the original array.  True values in this array
indicate that the stream should be kept.</p>
<p>If <code>keep</code> is specified, the returned array WILL NOT have the same shape as
the original.  Instead it will be a 2D array of decompressed streams- the
streams corresponding to True values in the <code>keep</code> mask.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>zgrp</code>
            </td>
            <td>
                  <code><span title="flacarray.zarr.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The open Group for reading.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, the communicator over which to
distribute the leading dimension.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_dist</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, assign blocks of these sizes to processes
when distributing the leading dimension.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>no_flatten</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, for single-stream arrays, leave the leading
dimension of (1,) in the result.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><a class="autorefs autorefs-internal" title="            flacarray.FlacArray (flacarray.array.FlacArray)" href="#flacarray.FlacArray">FlacArray</a></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A newly constructed FlacArray.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span>
<span class="normal">871</span>
<span class="normal">872</span>
<span class="normal">873</span>
<span class="normal">874</span>
<span class="normal">875</span>
<span class="normal">876</span>
<span class="normal">877</span>
<span class="normal">878</span>
<span class="normal">879</span>
<span class="normal">880</span>
<span class="normal">881</span>
<span class="normal">882</span>
<span class="normal">883</span>
<span class="normal">884</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@classmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">read_zarr</span><span class="p">(</span>
    <span class="bp">cls</span><span class="p">,</span>
    <span class="n">zgrp</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Construct a FlacArray from a Zarr Group.</span>

<span class="sd">    This function loads all information about the array from a zarr group.  If</span>
<span class="sd">    `mpi_comm` is specified, the created array is distributed over that</span>
<span class="sd">    communicator.</span>

<span class="sd">    If `mpi_dist` is specified, it should be an iterable with the number of leading</span>
<span class="sd">    dimension elements assigned to each process.  If None, the leading dimension</span>
<span class="sd">    will be distributed uniformly.</span>

<span class="sd">    If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">    as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">    indicate that the stream should be kept.</span>

<span class="sd">    If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">    the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">    streams corresponding to True values in the `keep` mask.</span>

<span class="sd">    Args:</span>
<span class="sd">        zgrp (zarr.Group):  The open Group for reading.</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        mpi_comm (MPI.Comm):  If specified, the communicator over which to</span>
<span class="sd">            distribute the leading dimension.</span>
<span class="sd">        mpi_dist (array):  If specified, assign blocks of these sizes to processes</span>
<span class="sd">            when distributing the leading dimension.</span>
<span class="sd">        no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">            dimension of (1,) in the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (FlacArray):  A newly constructed FlacArray.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">local_shape</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="p">,</span>
        <span class="n">compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="p">,</span>
        <span class="n">keep_indices</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">zarr_read_compressed</span><span class="p">(</span>
        <span class="n">zgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">dt</span> <span class="o">=</span> <span class="n">compressed_dtype</span><span class="p">(</span><span class="n">n_channels</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="p">,</span> <span class="n">stream_gains</span><span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">local_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">local_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_flatten</span><span class="p">:</span>
        <span class="c1"># Flatten</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">local_shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="n">local_shape</span>

    <span class="k">return</span> <span class="n">FlacArray</span><span class="p">(</span>
        <span class="kc">None</span><span class="p">,</span>
        <span class="n">shape</span><span class="o">=</span><span class="n">shape</span><span class="p">,</span>
        <span class="n">global_shape</span><span class="o">=</span><span class="n">global_shape</span><span class="p">,</span>
        <span class="n">compressed</span><span class="o">=</span><span class="n">compressed</span><span class="p">,</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">dt</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="o">=</span><span class="n">stream_starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="o">=</span><span class="n">stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="n">stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="n">stream_gains</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.to_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">to_array</span><span class="p">(</span><span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Decompress local data into a numpy array.</p>
<p>This uses the compressed representation to reconstruct a normal numpy
array.  The returned data type will be either int32, int64, float32, or
float64 depending on the original data type.</p>
<p>If <code>stream_slice</code> is specified, the returned array will have only that
range of samples in the final dimension.</p>
<p>If <code>keep</code> is specified, this should be a boolean array with the same shape
as the leading dimensions of the original array.  True values in this array
indicate that the stream should be kept.</p>
<p>If <code>keep</code> is specified, the returned array WILL NOT have the same shape as
the original.  Instead it will be a 2D array of decompressed streams- the
streams corresponding to True values in the <code>keep</code> mask.</p>
<p>If <code>keep_indices</code> is True and <code>keep</code> is specified, then a tuple of two values
is returned.  The first is the array of decompressed streams.  The second is
a list of tuples, each of which specifies the indices of the stream in the
original array.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_slice</code>
            </td>
            <td>
                  <code><span title="slice">slice</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A python slice with step size of one, indicating
the sample range to extract from each stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep_indices</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, also return the original indices of the
streams.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">to_array</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decompress local data into a numpy array.</span>

<span class="sd">    This uses the compressed representation to reconstruct a normal numpy</span>
<span class="sd">    array.  The returned data type will be either int32, int64, float32, or</span>
<span class="sd">    float64 depending on the original data type.</span>

<span class="sd">    If `stream_slice` is specified, the returned array will have only that</span>
<span class="sd">    range of samples in the final dimension.</span>

<span class="sd">    If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">    as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">    indicate that the stream should be kept.</span>

<span class="sd">    If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">    the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">    streams corresponding to True values in the `keep` mask.</span>

<span class="sd">    If `keep_indices` is True and `keep` is specified, then a tuple of two values</span>
<span class="sd">    is returned.  The first is the array of decompressed streams.  The second is</span>
<span class="sd">    a list of tuples, each of which specifies the indices of the stream in the</span>
<span class="sd">    original array.</span>

<span class="sd">    Args:</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        stream_slice (slice):  A python slice with step size of one, indicating</span>
<span class="sd">            the sample range to extract from each stream.</span>
<span class="sd">        keep_indices (bool):  If True, also return the original indices of the</span>
<span class="sd">            streams.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">first_samp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">last_samp</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">stream_slice</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">step</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;Only stream slices with a step size of 1 are supported&quot;</span>
            <span class="p">)</span>
        <span class="n">first_samp</span> <span class="o">=</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">start</span>
        <span class="n">last_samp</span> <span class="o">=</span> <span class="n">stream_slice</span><span class="o">.</span><span class="n">stop</span>

    <span class="n">arr</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">array_decompress_slice</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
        <span class="n">first_stream_sample</span><span class="o">=</span><span class="n">first_samp</span><span class="p">,</span>
        <span class="n">last_stream_sample</span><span class="o">=</span><span class="n">last_samp</span><span class="p">,</span>
        <span class="n">is_int64</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="p">(</span><span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">_flatten_single</span><span class="p">),</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">keep</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">keep_indices</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">arr</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.write_hdf5" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">write_hdf5</span><span class="p">(</span><span class="n">hgrp</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Write data to an HDF5 Group.</p>
<p>The internal object properties are written to an open HDF5 group.  If you
wish to use MPI I/O to write data to the group, then you must be using an MPI
enabled h5py and you should pass in a valid handle to the group on all
processes.</p>
<p>If the <code>FlacArray</code> is distributed over an MPI communicator, but the h5py
implementation does not support MPI I/O, then all data will be communicated
to the rank zero process for writing.  In this case, the <code>hgrp</code> argument should
be None except on the root process.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hgrp</code>
            </td>
            <td>
                  <code><span title="h5py.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The open Group for writing.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">write_hdf5</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hgrp</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Write data to an HDF5 Group.</span>

<span class="sd">    The internal object properties are written to an open HDF5 group.  If you</span>
<span class="sd">    wish to use MPI I/O to write data to the group, then you must be using an MPI</span>
<span class="sd">    enabled h5py and you should pass in a valid handle to the group on all</span>
<span class="sd">    processes.</span>

<span class="sd">    If the `FlacArray` is distributed over an MPI communicator, but the h5py</span>
<span class="sd">    implementation does not support MPI I/O, then all data will be communicated</span>
<span class="sd">    to the rank zero process for writing.  In this case, the `hgrp` argument should</span>
<span class="sd">    be None except on the root process.</span>

<span class="sd">    Args:</span>
<span class="sd">        hgrp (h5py.Group):  The open Group for writing.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">hdf5_write_compressed</span><span class="p">(</span>
        <span class="n">hgrp</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h4 id="flacarray.FlacArray.write_zarr" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-method"></code>            <code class="highlight language-python"><span class="n">write_zarr</span><span class="p">(</span><span class="n">zgrp</span><span class="p">)</span></code>

</h4>


    <div class="doc doc-contents ">

        <p>Write data to an Zarr Group.</p>
<p>The internal object properties are written to an open zarr group.</p>
<p>If the <code>FlacArray</code> is distributed over an MPI communicator, then all data will
be communicated to the rank zero process for writing.  In this case, the <code>zgrp</code>
argument should be None except on the root process.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>zgrp</code>
            </td>
            <td>
                  <code><span title="flacarray.zarr.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The open Group for writing.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/array.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">write_zarr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">zgrp</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Write data to an Zarr Group.</span>

<span class="sd">    The internal object properties are written to an open zarr group.</span>

<span class="sd">    If the `FlacArray` is distributed over an MPI communicator, then all data will</span>
<span class="sd">    be communicated to the rank zero process for writing.  In this case, the `zgrp`</span>
<span class="sd">    argument should be None except on the root process.</span>

<span class="sd">    Args:</span>
<span class="sd">        zgrp (zarr.Group):  The open Group for writing.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_is_int64</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">zarr_write_compressed</span><span class="p">(</span>
        <span class="n">zgrp</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_leading_shape</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_leading_shape</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_size</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_starts</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_stream_starts</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_offsets</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_stream_gains</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_compressed</span><span class="o">.</span><span class="n">nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_global_proc_nbytes</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_comm</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h2 id="direct-io">Direct I/O</h2>
<p>Sometimes code has no need to store compressed arrays in memory. Instead, it
may be desirable to have full arrays in memory and compressed arrays on disk.
In those situations, you can use several helper functions to write and read
numpy arrays directly to / from files.</p>
<h3 id="hdf5">HDF5</h3>
<p>You can write to / read from an h5py Group using functions in the <code>hdf5</code>
submodule.</p>


<div class="doc doc-object doc-function">


<h3 id="flacarray.hdf5.write_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">hdf5</span><span class="o">.</span><span class="n">write_array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">hgrp</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Compress a numpy array and write to an HDF5 group.</p>
<p>This function is useful if you do not need to access the compressed array in memory
and only wish to write it directly to HDF5.  The input array is compressed and then
the <code>write_compressed()</code> function is called.</p>
<p>If the input array is int32 or int64, the compression is lossless and the compressed
bytes and ancillary data is written to datasets within the output group.  If the
array is float32 or float64, either the <code>quanta</code> or <code>precision</code> must be specified.
See discussion in the <code>FlacArray</code> class documentation about how the offsets and
gains are computed for a given quanta.  The offsets and gains are also written as
datasets within the output group.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>arr</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input numpy array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>hgrp</code>
            </td>
            <td>
                  <code><span title="h5py.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Group to use.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compression level (0-8).</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quanta</code>
            </td>
            <td>
                  <code>(<span title="float">float</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For floating point data, the floating point
increment of each 32bit integer value.  Optionally an iterable of
increments, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code>(<span title="int">int</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of significant digits to retain in
float-to-int conversion.  Alternative to <code>quanta</code>.  Optionally an
iterable of values, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, the input array is assumed to be
distributed across the communicator at the leading dimension.  The
local piece of the array is passed in on each process.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/hdf5.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">write_array</span><span class="p">(</span>
    <span class="n">arr</span><span class="p">,</span> <span class="n">hgrp</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compress a numpy array and write to an HDF5 group.</span>

<span class="sd">    This function is useful if you do not need to access the compressed array in memory</span>
<span class="sd">    and only wish to write it directly to HDF5.  The input array is compressed and then</span>
<span class="sd">    the `write_compressed()` function is called.</span>

<span class="sd">    If the input array is int32 or int64, the compression is lossless and the compressed</span>
<span class="sd">    bytes and ancillary data is written to datasets within the output group.  If the</span>
<span class="sd">    array is float32 or float64, either the `quanta` or `precision` must be specified.</span>
<span class="sd">    See discussion in the `FlacArray` class documentation about how the offsets and</span>
<span class="sd">    gains are computed for a given quanta.  The offsets and gains are also written as</span>
<span class="sd">    datasets within the output group.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (array):  The input numpy array.</span>
<span class="sd">        hgrp (h5py.Group):  The Group to use.</span>
<span class="sd">        level (int):  Compression level (0-8).</span>
<span class="sd">        quanta (float, array):  For floating point data, the floating point</span>
<span class="sd">            increment of each 32bit integer value.  Optionally an iterable of</span>
<span class="sd">            increments, one per stream.</span>
<span class="sd">        precision (int, array):  Number of significant digits to retain in</span>
<span class="sd">            float-to-int conversion.  Alternative to `quanta`.  Optionally an</span>
<span class="sd">            iterable of values, one per stream.</span>
<span class="sd">        mpi_comm (MPI.Comm):  If specified, the input array is assumed to be</span>
<span class="sd">            distributed across the communicator at the leading dimension.  The</span>
<span class="sd">            local piece of the array is passed in on each process.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">have_hdf5</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;h5py is not importable, cannot write to HDF5&quot;</span><span class="p">)</span>

    <span class="c1"># Get the global shape of the array</span>
    <span class="n">global_props</span> <span class="o">=</span> <span class="n">global_array_properties</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">)</span>
    <span class="n">global_shape</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span>
    <span class="n">mpi_dist</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;dist&quot;</span><span class="p">]</span>

    <span class="c1"># Get the number of channels</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="ow">or</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Compress our local piece of the array</span>
    <span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">gains</span> <span class="o">=</span> <span class="n">array_compress</span><span class="p">(</span>
        <span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="n">quanta</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span>
    <span class="p">)</span>

    <span class="n">local_nbytes</span> <span class="o">=</span> <span class="n">compressed</span><span class="o">.</span><span class="n">nbytes</span>
    <span class="n">global_nbytes</span><span class="p">,</span> <span class="n">global_proc_bytes</span><span class="p">,</span> <span class="n">global_starts</span> <span class="o">=</span> <span class="n">global_bytes</span><span class="p">(</span>
        <span class="n">local_nbytes</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">mpi_comm</span>
    <span class="p">)</span>
    <span class="n">stream_size</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">global_leading_shape</span> <span class="o">=</span> <span class="n">global_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">write_compressed</span><span class="p">(</span>
        <span class="n">hgrp</span><span class="p">,</span>
        <span class="n">leading_shape</span><span class="p">,</span>
        <span class="n">global_leading_shape</span><span class="p">,</span>
        <span class="n">stream_size</span><span class="p">,</span>
        <span class="n">starts</span><span class="p">,</span>
        <span class="n">global_starts</span><span class="p">,</span>
        <span class="n">nbytes</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">,</span>
        <span class="n">gains</span><span class="p">,</span>
        <span class="n">compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="n">local_nbytes</span><span class="p">,</span>
        <span class="n">global_nbytes</span><span class="p">,</span>
        <span class="n">global_proc_bytes</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flacarray.hdf5.read_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">hdf5</span><span class="o">.</span><span class="n">read_array</span><span class="p">(</span><span class="n">hgrp</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Load a numpy array from compressed HDF5.</p>
<p>This function is useful if you do not need to store a compressed representation
of the array in memory.  Each stream will be read individually from the file and
the desired slice decompressed.  This avoids storing the full compressed data.</p>
<p>This function acts as a dispatch to the correct version of the reading function.
The function is selected based on the format version string in the data.</p>
<p>If <code>stream_slice</code> is specified, the returned array will have only that
range of samples in the final dimension.</p>
<p>If <code>keep</code> is specified, this should be a boolean array with the same shape
as the leading dimensions of the original array.  True values in this array
indicate that the stream should be kept.</p>
<p>If <code>keep</code> is specified, the returned array WILL NOT have the same shape as
the original.  Instead it will be a 2D array of decompressed streams- the
streams corresponding to True values in the <code>keep</code> mask.</p>
<p>If <code>keep_indices</code> is True and <code>keep</code> is specified, then an additional list
is returned containing the indices of each stream that was kept.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>hgrp</code>
            </td>
            <td>
                  <code><span title="h5py.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The group to read.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_slice</code>
            </td>
            <td>
                  <code><span title="slice">slice</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A python slice with step size of one, indicating
the sample range to extract from each stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep_indices</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, also return the original indices of the
streams.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optional MPI communicator over which to distribute
the leading dimension of the array.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_dist</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optional list of tuples specifying the first / last
element of the leading dimension to assign to each process.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The loaded and decompressed data OR the array and the kept indices.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/hdf5.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">read_array</span><span class="p">(</span>
    <span class="n">hgrp</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a numpy array from compressed HDF5.</span>

<span class="sd">    This function is useful if you do not need to store a compressed representation</span>
<span class="sd">    of the array in memory.  Each stream will be read individually from the file and</span>
<span class="sd">    the desired slice decompressed.  This avoids storing the full compressed data.</span>

<span class="sd">    This function acts as a dispatch to the correct version of the reading function.</span>
<span class="sd">    The function is selected based on the format version string in the data.</span>

<span class="sd">    If `stream_slice` is specified, the returned array will have only that</span>
<span class="sd">    range of samples in the final dimension.</span>

<span class="sd">    If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">    as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">    indicate that the stream should be kept.</span>

<span class="sd">    If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">    the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">    streams corresponding to True values in the `keep` mask.</span>

<span class="sd">    If `keep_indices` is True and `keep` is specified, then an additional list</span>
<span class="sd">    is returned containing the indices of each stream that was kept.</span>

<span class="sd">    Args:</span>
<span class="sd">        hgrp (h5py.Group):  The group to read.</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        stream_slice (slice):  A python slice with step size of one, indicating</span>
<span class="sd">            the sample range to extract from each stream.</span>
<span class="sd">        keep_indices (bool):  If True, also return the original indices of the</span>
<span class="sd">            streams.</span>
<span class="sd">        mpi_comm (MPI.Comm):  The optional MPI communicator over which to distribute</span>
<span class="sd">            the leading dimension of the array.</span>
<span class="sd">        mpi_dist (list):  The optional list of tuples specifying the first / last</span>
<span class="sd">            element of the leading dimension to assign to each process.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (array):  The loaded and decompressed data OR the array and the kept indices.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">have_hdf5</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;h5py is not importable, cannot write to HDF5&quot;</span><span class="p">)</span>

    <span class="n">format_version</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">hgrp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;flacarray_format_version&quot;</span> <span class="ow">in</span> <span class="n">hgrp</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
            <span class="n">format_version</span> <span class="o">=</span> <span class="n">hgrp</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;flacarray_format_version&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mpi_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">format_version</span> <span class="o">=</span> <span class="n">mpi_comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">format_version</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">format_version</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;h5py Group does not contain a FlacArray&quot;</span><span class="p">)</span>

    <span class="n">mod_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;.hdf5_load_v</span><span class="si">{</span><span class="n">format_version</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">mod_name</span><span class="p">,</span> <span class="n">package</span><span class="o">=</span><span class="s2">&quot;flacarray&quot;</span><span class="p">)</span>
    <span class="n">read_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s2">&quot;read_array&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_func</span><span class="p">(</span>
        <span class="n">hgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
        <span class="n">stream_slice</span><span class="o">=</span><span class="n">stream_slice</span><span class="p">,</span>
        <span class="n">keep_indices</span><span class="o">=</span><span class="n">keep_indices</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><h3 id="zarr">Zarr</h3>
<p>You can write to / read from a zarr hierarch Group using functions in the
<code>zarr</code> submodule.</p>


<div class="doc doc-object doc-function">


<h3 id="flacarray.zarr.write_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">zarr</span><span class="o">.</span><span class="n">write_array</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">zgrp</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Compress a numpy array and write to an Zarr group.</p>
<p>This function is useful if you do not need to access the compressed array in memory
and only wish to write it directly to Zarr files.  The input array is compressed
and then the <code>write_compressed()</code> function is called.</p>
<p>If the input array is int32 or int64, the compression is lossless and the compressed
bytes and ancillary data is written to datasets within the output group.  If the
array is float32 or float64, either the <code>quanta</code> or <code>precision</code> must be specified.
See discussion in the <code>FlacArray</code> class documentation about how the offsets and
gains are computed for a given quanta.  The offsets and gains are also written as
datasets within the output group.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>arr</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input numpy array.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>zgrp</code>
            </td>
            <td>
                  <code><span title="zarr.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The Group to use.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compression level (0-8).</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quanta</code>
            </td>
            <td>
                  <code>(<span title="float">float</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For floating point data, the floating point
increment of each 32bit integer value.  Optionally an iterable of
increments, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code>(<span title="int">int</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of significant digits to retain in
float-to-int conversion.  Alternative to <code>quanta</code>.  Optionally an
iterable of values, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If specified, the input array is assumed to be
distributed across the communicator at the leading dimension.  The
local piece of the array is passed in on each process.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>None</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/zarr.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">write_array</span><span class="p">(</span>
    <span class="n">arr</span><span class="p">,</span> <span class="n">zgrp</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compress a numpy array and write to an Zarr group.</span>

<span class="sd">    This function is useful if you do not need to access the compressed array in memory</span>
<span class="sd">    and only wish to write it directly to Zarr files.  The input array is compressed</span>
<span class="sd">    and then the `write_compressed()` function is called.</span>

<span class="sd">    If the input array is int32 or int64, the compression is lossless and the compressed</span>
<span class="sd">    bytes and ancillary data is written to datasets within the output group.  If the</span>
<span class="sd">    array is float32 or float64, either the `quanta` or `precision` must be specified.</span>
<span class="sd">    See discussion in the `FlacArray` class documentation about how the offsets and</span>
<span class="sd">    gains are computed for a given quanta.  The offsets and gains are also written as</span>
<span class="sd">    datasets within the output group.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (array):  The input numpy array.</span>
<span class="sd">        zgrp (zarr.Group):  The Group to use.</span>
<span class="sd">        level (int):  Compression level (0-8).</span>
<span class="sd">        quanta (float, array):  For floating point data, the floating point</span>
<span class="sd">            increment of each 32bit integer value.  Optionally an iterable of</span>
<span class="sd">            increments, one per stream.</span>
<span class="sd">        precision (int, array):  Number of significant digits to retain in</span>
<span class="sd">            float-to-int conversion.  Alternative to `quanta`.  Optionally an</span>
<span class="sd">            iterable of values, one per stream.</span>
<span class="sd">        mpi_comm (MPI.Comm):  If specified, the input array is assumed to be</span>
<span class="sd">            distributed across the communicator at the leading dimension.  The</span>
<span class="sd">            local piece of the array is passed in on each process.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        None</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">have_zarr</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;zarr is not importable, cannot write to zarr.Group&quot;</span><span class="p">)</span>

    <span class="c1"># Get the global shape of the array</span>
    <span class="n">global_props</span> <span class="o">=</span> <span class="n">global_array_properties</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">)</span>
    <span class="n">global_shape</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span>
    <span class="n">mpi_dist</span> <span class="o">=</span> <span class="n">global_props</span><span class="p">[</span><span class="s2">&quot;dist&quot;</span><span class="p">]</span>

    <span class="c1"># Get the number of channels</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="ow">or</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">n_channels</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="c1"># Compress our local piece of the array</span>
    <span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">gains</span> <span class="o">=</span> <span class="n">array_compress</span><span class="p">(</span>
        <span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="n">level</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="n">quanta</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span>
    <span class="p">)</span>

    <span class="n">local_nbytes</span> <span class="o">=</span> <span class="n">compressed</span><span class="o">.</span><span class="n">nbytes</span>
    <span class="n">global_nbytes</span><span class="p">,</span> <span class="n">global_proc_bytes</span><span class="p">,</span> <span class="n">global_starts</span> <span class="o">=</span> <span class="n">global_bytes</span><span class="p">(</span>
        <span class="n">local_nbytes</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">mpi_comm</span>
    <span class="p">)</span>
    <span class="n">stream_size</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">leading_shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">global_leading_shape</span> <span class="o">=</span> <span class="n">global_shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">write_compressed</span><span class="p">(</span>
        <span class="n">zgrp</span><span class="p">,</span>
        <span class="n">leading_shape</span><span class="p">,</span>
        <span class="n">global_leading_shape</span><span class="p">,</span>
        <span class="n">stream_size</span><span class="p">,</span>
        <span class="n">starts</span><span class="p">,</span>
        <span class="n">global_starts</span><span class="p">,</span>
        <span class="n">nbytes</span><span class="p">,</span>
        <span class="n">offsets</span><span class="p">,</span>
        <span class="n">gains</span><span class="p">,</span>
        <span class="n">compressed</span><span class="p">,</span>
        <span class="n">n_channels</span><span class="p">,</span>
        <span class="n">local_nbytes</span><span class="p">,</span>
        <span class="n">global_nbytes</span><span class="p">,</span>
        <span class="n">global_proc_bytes</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flacarray.zarr.read_array" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">zarr</span><span class="o">.</span><span class="n">read_array</span><span class="p">(</span><span class="n">zgrp</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Load a numpy array from a compressed Zarr group.</p>
<p>This function is useful if you do not need to store a compressed representation
of the array in memory.  Each stream will be read individually from the file and
the desired slice decompressed.  This avoids storing the full compressed data.</p>
<p>This function acts as a dispatch to the correct version of the reading function.
The function is selected based on the format version string in the data.</p>
<p>If <code>stream_slice</code> is specified, the returned array will have only that
range of samples in the final dimension.</p>
<p>If <code>keep</code> is specified, this should be a boolean array with the same shape
as the leading dimensions of the original array.  True values in this array
indicate that the stream should be kept.</p>
<p>If <code>keep</code> is specified, the returned array WILL NOT have the same shape as
the original.  Instead it will be a 2D array of decompressed streams- the
streams corresponding to True values in the <code>keep</code> mask.</p>
<p>If <code>keep_indices</code> is True and <code>keep</code> is specified, then an additional list
is returned containing the indices of each stream that was kept.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>zgrp</code>
            </td>
            <td>
                  <code><span title="zarr.Group">Group</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The group to read.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_slice</code>
            </td>
            <td>
                  <code><span title="slice">slice</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>A python slice with step size of one, indicating
the sample range to extract from each stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep_indices</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, also return the original indices of the
streams.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optional MPI communicator over which to distribute
the leading dimension of the array.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mpi_dist</code>
            </td>
            <td>
                  <code><span title="list">list</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optional list of tuples specifying the first / last
element of the leading dimension to assign to each process.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>no_flatten</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, for single-stream arrays, leave the leading
dimension of (1,) in the result.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The loaded and decompressed data OR the array and the kept indices.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/zarr.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">read_array</span><span class="p">(</span>
    <span class="n">zgrp</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">stream_slice</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keep_indices</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">mpi_comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">mpi_dist</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Load a numpy array from a compressed Zarr group.</span>

<span class="sd">    This function is useful if you do not need to store a compressed representation</span>
<span class="sd">    of the array in memory.  Each stream will be read individually from the file and</span>
<span class="sd">    the desired slice decompressed.  This avoids storing the full compressed data.</span>

<span class="sd">    This function acts as a dispatch to the correct version of the reading function.</span>
<span class="sd">    The function is selected based on the format version string in the data.</span>

<span class="sd">    If `stream_slice` is specified, the returned array will have only that</span>
<span class="sd">    range of samples in the final dimension.</span>

<span class="sd">    If `keep` is specified, this should be a boolean array with the same shape</span>
<span class="sd">    as the leading dimensions of the original array.  True values in this array</span>
<span class="sd">    indicate that the stream should be kept.</span>

<span class="sd">    If `keep` is specified, the returned array WILL NOT have the same shape as</span>
<span class="sd">    the original.  Instead it will be a 2D array of decompressed streams- the</span>
<span class="sd">    streams corresponding to True values in the `keep` mask.</span>

<span class="sd">    If `keep_indices` is True and `keep` is specified, then an additional list</span>
<span class="sd">    is returned containing the indices of each stream that was kept.</span>

<span class="sd">    Args:</span>
<span class="sd">        zgrp (zarr.Group):  The group to read.</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        stream_slice (slice):  A python slice with step size of one, indicating</span>
<span class="sd">            the sample range to extract from each stream.</span>
<span class="sd">        keep_indices (bool):  If True, also return the original indices of the</span>
<span class="sd">            streams.</span>
<span class="sd">        mpi_comm (MPI.Comm):  The optional MPI communicator over which to distribute</span>
<span class="sd">            the leading dimension of the array.</span>
<span class="sd">        mpi_dist (list):  The optional list of tuples specifying the first / last</span>
<span class="sd">            element of the leading dimension to assign to each process.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>
<span class="sd">        no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">            dimension of (1,) in the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (array):  The loaded and decompressed data OR the array and the kept indices.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">have_zarr</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;zarr is not importable, cannot write to a Zarr Group&quot;</span><span class="p">)</span>

    <span class="n">format_version</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">zgrp</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="s2">&quot;flacarray_format_version&quot;</span> <span class="ow">in</span> <span class="n">zgrp</span><span class="o">.</span><span class="n">attrs</span><span class="p">:</span>
            <span class="n">format_version</span> <span class="o">=</span> <span class="n">zgrp</span><span class="o">.</span><span class="n">attrs</span><span class="p">[</span><span class="s2">&quot;flacarray_format_version&quot;</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">mpi_comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">format_version</span> <span class="o">=</span> <span class="n">mpi_comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">format_version</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">format_version</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Zarr Group does not contain a FlacArray&quot;</span><span class="p">)</span>

    <span class="n">mod_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;.zarr_load_v</span><span class="si">{</span><span class="n">format_version</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">importlib</span><span class="o">.</span><span class="n">import_module</span><span class="p">(</span><span class="n">mod_name</span><span class="p">,</span> <span class="n">package</span><span class="o">=</span><span class="s2">&quot;flacarray&quot;</span><span class="p">)</span>
    <span class="n">read_func</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="s2">&quot;read_array&quot;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">read_func</span><span class="p">(</span>
        <span class="n">zgrp</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="n">keep</span><span class="p">,</span>
        <span class="n">stream_slice</span><span class="o">=</span><span class="n">stream_slice</span><span class="p">,</span>
        <span class="n">keep_indices</span><span class="o">=</span><span class="n">keep_indices</span><span class="p">,</span>
        <span class="n">mpi_comm</span><span class="o">=</span><span class="n">mpi_comm</span><span class="p">,</span>
        <span class="n">mpi_dist</span><span class="o">=</span><span class="n">mpi_dist</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><h2 id="interactive-tools">Interactive Tools</h2>
<p>The <code>flacarray.demo</code> submodule contains a few helper functions that are not
imported by default. You will need to have optional dependencies (matplotlib)
installed to use the visualization tools. For testing, it is convenient to
generate arrays consisting of random timestreams with some structure. The
<code>create_fake_data</code> function can be used for this.</p>


<div class="doc doc-object doc-function">


<h3 id="flacarray.demo.create_fake_data" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">demo</span><span class="o">.</span><span class="n">create_fake_data</span><span class="p">(</span><span class="n">local_shape</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123456789</span><span class="p">,</span> <span class="n">comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dc_sigma</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Create fake random data for testing.</p>
<p>This is a helper function to generate some random data for testing.
if <code>sigma</code> is None, uniform randoms are return.  If sigma is not None,
samples drawn from a Gaussian distribution are returned.</p>
<p>If <code>comm</code> is not None, the data is created on one process and then pieces are
distributed among the processes.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>local_shape</code>
            </td>
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The local shape of the data on this process.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sigma</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The width of the distribution or None.</p>
              </div>
            </td>
            <td>
                  <code>1.0</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dtype</code>
            </td>
            <td>
                  <code><span title="numpy.dtype">dtype</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The data type of the returned array.</p>
              </div>
            </td>
            <td>
                  <code><span title="numpy.float64">float64</span></code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>seed</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The optional seed for np.random.</p>
              </div>
            </td>
            <td>
                  <code>123456789</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>comm</code>
            </td>
            <td>
                  <code><span title="MPI.Comm">Comm</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The MPI communicator or None.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>(The random data on the local process, MPI distribution).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/demo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">create_fake_data</span><span class="p">(</span>
    <span class="n">local_shape</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123456789</span><span class="p">,</span> <span class="n">comm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">dc_sigma</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Create fake random data for testing.</span>

<span class="sd">    This is a helper function to generate some random data for testing.</span>
<span class="sd">    if `sigma` is None, uniform randoms are return.  If sigma is not None,</span>
<span class="sd">    samples drawn from a Gaussian distribution are returned.</span>

<span class="sd">    If `comm` is not None, the data is created on one process and then pieces are</span>
<span class="sd">    distributed among the processes.</span>

<span class="sd">    Args:</span>
<span class="sd">        local_shape (tuple):  The local shape of the data on this process.</span>
<span class="sd">        sigma (float):  The width of the distribution or None.</span>
<span class="sd">        dtype (np.dtype):  The data type of the returned array.</span>
<span class="sd">        seed (int):  The optional seed for np.random.</span>
<span class="sd">        comm (MPI.Comm):  The MPI communicator or None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (tuple):  (The random data on the local process, MPI distribution).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">comm</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">rank</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">rank</span>

    <span class="c1"># Get the global array properties</span>
    <span class="n">gprops</span> <span class="o">=</span> <span class="n">global_array_properties</span><span class="p">(</span><span class="n">local_shape</span><span class="p">,</span> <span class="n">comm</span><span class="p">)</span>
    <span class="n">shape</span> <span class="o">=</span> <span class="n">gprops</span><span class="p">[</span><span class="s2">&quot;shape&quot;</span><span class="p">]</span>
    <span class="n">mpi_dist</span> <span class="o">=</span> <span class="n">gprops</span><span class="p">[</span><span class="s2">&quot;dist&quot;</span><span class="p">]</span>

    <span class="n">flatshape</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">stream_size</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">leading_shape</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">leading_shape_ext</span> <span class="o">=</span> <span class="n">leading_shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">global_data</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">sigma</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Uniform randoms. Verify that we can fully encode the high / low</span>
            <span class="c1"># values by setting a few samples to those extremes.</span>
            <span class="k">if</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span> <span class="ow">or</span> <span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">):</span>
                <span class="n">low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
                <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
                <span class="n">flat_data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">integers</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">flatshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span>
                <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">min</span>
                <span class="n">high</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">finfo</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">max</span>
                <span class="n">flat_data</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span>
                    <span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">flatshape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span>
                <span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">low</span>
            <span class="n">flat_data</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">high</span>
            <span class="n">global_data</span> <span class="o">=</span> <span class="n">flat_data</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Construct a random DC level for each stream.</span>
            <span class="k">if</span> <span class="n">dc_sigma</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">dc</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">dc</span> <span class="o">=</span> <span class="n">dc_sigma</span> <span class="o">*</span> <span class="n">sigma</span> <span class="o">*</span> <span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">leading_shape_ext</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span>

            <span class="c1"># Construct a simple low frequency waveform (assume 1Hz sampling)</span>
            <span class="n">wave</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">stream_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">stream_size</span><span class="p">)</span>
            <span class="n">minf</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">/</span> <span class="n">stream_size</span>
            <span class="k">for</span> <span class="n">freq</span><span class="p">,</span> <span class="n">amp</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">3</span> <span class="o">*</span> <span class="n">minf</span><span class="p">,</span> <span class="n">minf</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">,</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">sigma</span><span class="p">]):</span>
                <span class="n">wave</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">amp</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span> <span class="o">*</span> <span class="n">freq</span> <span class="o">*</span> <span class="n">t</span><span class="p">)</span>

            <span class="c1"># Initialize all streams to a scaled version of this waveform plus</span>
            <span class="c1"># the DC level</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">random</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">leading_shape_ext</span><span class="p">)</span>
            <span class="n">global_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">leading_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">global_data</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">dc</span>
                <span class="n">global_data</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">wave</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">leading_slc</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">leading_shape</span><span class="p">])</span>
                <span class="n">global_data</span><span class="p">[</span><span class="n">leading_slc</span><span class="p">]</span> <span class="o">=</span> <span class="n">dc</span>
                <span class="n">global_data</span><span class="p">[</span><span class="n">leading_slc</span><span class="p">]</span> <span class="o">+=</span> <span class="n">scale</span> <span class="o">*</span> <span class="n">wave</span>

            <span class="c1"># Add some Gaussian random noise to each stream</span>
            <span class="n">global_data</span><span class="p">[:]</span> <span class="o">+=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">flatshape</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">comm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">global_data</span> <span class="o">=</span> <span class="n">comm</span><span class="o">.</span><span class="n">bcast</span><span class="p">(</span><span class="n">global_data</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># Extract our local piece of the global data</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">leading_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">leading_shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">leading_shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">global_data</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">local_start</span> <span class="o">=</span> <span class="n">mpi_dist</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">local_stop</span> <span class="o">=</span> <span class="n">mpi_dist</span><span class="p">[</span><span class="n">rank</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">local_slice</span> <span class="o">=</span> <span class="p">[</span><span class="nb">slice</span><span class="p">(</span><span class="n">local_start</span><span class="p">,</span> <span class="n">local_stop</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]</span>
        <span class="n">local_slice</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]])</span>
        <span class="n">local_slice</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">local_slice</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">global_data</span><span class="p">[</span><span class="n">local_slice</span><span class="p">]</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">mpi_dist</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><p>Most data arrays in practice have 2 or 3 dimensions. If the number of streams
is relatively small, then an uncompressed array can be plotted with the
<code>plot_data</code> function.</p>


<div class="doc doc-object doc-function">


<h3 id="flacarray.demo.plot_data" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">demo</span><span class="o">.</span><span class="n">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_slc</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">


            <details class="quote">
              <summary>Source code in <code>flacarray/demo.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">plot_data</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_slc</span><span class="o">=</span><span class="nb">slice</span><span class="p">(</span><span class="kc">None</span><span class="p">),</span> <span class="n">file</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># We only import matplotlib if we are actually going to make some plots.</span>
    <span class="c1"># This is not a required package.</span>
    <span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Can only plot 1D and 2D arrays of streams&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">plot_rows</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="n">plot_cols</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">plot_rows</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">plot_cols</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plot_rows</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">plot_cols</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">fig_dpi</span> <span class="o">=</span> <span class="mi">100</span>
    <span class="n">fig_width</span> <span class="o">=</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">plot_cols</span>
    <span class="n">fig_height</span> <span class="o">=</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">plot_rows</span>
    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="n">fig_width</span><span class="p">,</span> <span class="n">fig_height</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="n">fig_dpi</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="c1"># Single stream</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">stream_slc</span><span class="p">])</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="c1"># 1-D array of streams, plot vertically</span>
        <span class="k">for</span> <span class="n">iplot</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">plot_rows</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">iplot</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">iplot</span><span class="p">,</span> <span class="n">stream_slc</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="c1"># 2-D array of streams, plot in a grid</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">plot_rows</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">plot_cols</span><span class="p">):</span>
                <span class="n">slc</span> <span class="o">=</span> <span class="p">(</span><span class="n">col</span><span class="p">,</span> <span class="n">row</span><span class="p">,</span> <span class="n">stream_slc</span><span class="p">)</span>
                <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span>
                    <span class="n">plot_rows</span><span class="p">,</span> <span class="n">plot_cols</span><span class="p">,</span> <span class="n">row</span> <span class="o">*</span> <span class="n">plot_cols</span> <span class="o">+</span> <span class="n">col</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s2">&quot;auto&quot;</span>
                <span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">slc</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div><h2 id="low-level-tools">Low-Level Tools</h2>
<p>For specialized use cases, you can also work directly with the compressed
bytestream and auxiliary arrays and convert to / from numpy arrays.</p>


<div class="doc doc-object doc-function">


<h3 id="flacarray.compress.array_compress" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">compress</span><span class="o">.</span><span class="n">array_compress</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Compress a numpy array with optional floating point conversion.</p>
<p>If <code>arr</code> is an int32 array, the returned stream offsets and gains will be None.
if <code>arr</code> is an int64 array, the returned stream offsets and gains will be None and
the calling code is responsible for tracking that the compressed bytes are
associated with a 64bit stream.</p>
<p>If the input array is float32 or float64, exactly one of quanta or precision
must be specified.  Both float32 and float64 data will have floating point offset
and gain arrays returned.  See discussion in the <code>FlacArray</code> class documentation
about how the offsets and gains are computed for a given quanta.</p>
<p>The shape of the returned auxiliary arrays (starts, nbytes, etc) will have a shape
corresponding to the leading shape of the input array.  If the input array is a
single stream, the returned auxiliary information will be arrays with a single
element.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>arr</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The input array data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Compression level (0-8).</p>
              </div>
            </td>
            <td>
                  <code>5</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>quanta</code>
            </td>
            <td>
                  <code>(<span title="float">float</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>For floating point data, the floating point
increment of each integer value.  Optionally an array of increments,
one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>precision</code>
            </td>
            <td>
                  <code>(<span title="int">int</span>, <span title="flacarray.array">array</span>)</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of significant digits to retain in
float-to-int conversion.  Alternative to <code>quanta</code>.  Optionally an
iterable of values, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The (compressed bytes, stream starts, stream_nbytes, stream offsets,
stream gains)</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/compress.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">array_compress</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compress a numpy array with optional floating point conversion.</span>

<span class="sd">    If `arr` is an int32 array, the returned stream offsets and gains will be None.</span>
<span class="sd">    if `arr` is an int64 array, the returned stream offsets and gains will be None and</span>
<span class="sd">    the calling code is responsible for tracking that the compressed bytes are</span>
<span class="sd">    associated with a 64bit stream.</span>

<span class="sd">    If the input array is float32 or float64, exactly one of quanta or precision</span>
<span class="sd">    must be specified.  Both float32 and float64 data will have floating point offset</span>
<span class="sd">    and gain arrays returned.  See discussion in the `FlacArray` class documentation</span>
<span class="sd">    about how the offsets and gains are computed for a given quanta.</span>

<span class="sd">    The shape of the returned auxiliary arrays (starts, nbytes, etc) will have a shape</span>
<span class="sd">    corresponding to the leading shape of the input array.  If the input array is a</span>
<span class="sd">    single stream, the returned auxiliary information will be arrays with a single</span>
<span class="sd">    element.</span>

<span class="sd">    Args:</span>
<span class="sd">        arr (numpy.ndarray):  The input array data.</span>
<span class="sd">        level (int):  Compression level (0-8).</span>
<span class="sd">        quanta (float, array):  For floating point data, the floating point</span>
<span class="sd">            increment of each integer value.  Optionally an array of increments,</span>
<span class="sd">            one per stream.</span>
<span class="sd">        precision (int, array):  Number of significant digits to retain in</span>
<span class="sd">            float-to-int conversion.  Alternative to `quanta`.  Optionally an</span>
<span class="sd">            iterable of values, one per stream.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (tuple): The (compressed bytes, stream starts, stream_nbytes, stream offsets,</span>
<span class="sd">            stream gains)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot compress a zero-sized array!&quot;</span><span class="p">)</span>
    <span class="n">leading_shape</span> <span class="o">=</span> <span class="n">arr</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="ow">or</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">):</span>
        <span class="c1"># Floating point data</span>
        <span class="k">if</span> <span class="n">quanta</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">precision</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Compressing floating point data (&#39;</span><span class="si">{</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&#39;) &quot;</span>
            <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;requires specifying either quanta or precision.&quot;</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">quanta</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">precision</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Cannot set both quanta and precision&quot;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">nq</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">quanta</span><span class="p">)</span>
                <span class="c1"># This is an array</span>
                <span class="k">if</span> <span class="n">nq</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">leading_shape</span><span class="p">:</span>
                    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;If not a scalar, quanta must have the same shape as the &quot;</span>
                    <span class="n">msg</span> <span class="o">+=</span> <span class="s2">&quot;leading dimensions of the array&quot;</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
                <span class="n">dquanta</span> <span class="o">=</span> <span class="n">quanta</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">TypeError</span><span class="p">:</span>
                <span class="c1"># This is a scalar, applied to all detectors</span>
                <span class="n">dquanta</span> <span class="o">=</span> <span class="n">quanta</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">leading_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># We are using precision instead</span>
            <span class="n">dquanta</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">idata</span><span class="p">,</span> <span class="n">foff</span><span class="p">,</span> <span class="n">gains</span> <span class="o">=</span> <span class="n">float_to_int</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">quanta</span><span class="o">=</span><span class="n">dquanta</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
        <span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">)</span> <span class="o">=</span> <span class="n">encode_flac</span><span class="p">(</span>
            <span class="n">idata</span><span class="p">,</span> <span class="n">level</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">foff</span><span class="p">,</span> <span class="n">gains</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span> <span class="ow">or</span> <span class="n">arr</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">):</span>
        <span class="c1"># Integer data</span>
        <span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">)</span> <span class="o">=</span> <span class="n">encode_flac</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">level</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unsupported data type &#39;</span><span class="si">{</span><span class="n">arr</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flacarray.decompress.array_decompress" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">decompress</span><span class="o">.</span><span class="n">array_decompress</span><span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">stream_size</span><span class="p">,</span> <span class="n">stream_starts</span><span class="p">,</span> <span class="n">stream_nbytes</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_gains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">first_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_int64</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Decompress a FLAC encoded array and restore original data type.</p>
<p>If both <code>stream_gains</code> and <code>stream_offsets</code> are specified, the output will be
floating point data.  If neither is specified, the output will be integer data.
It is an error to specify only one of those options.</p>
<p>The compressed byte stream might contain either int32 or int64 data, and the calling
code is responsible for tracking this.  The <code>is_int64</code> parameter should be set to
True if the byte stream contains 64bit integers.</p>
<p>To decompress a subset of samples in all streams, specify the <code>first_stream_sample</code>
and <code>last_stream_sample</code> values.  None values or negative values disable this
feature.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>compressed</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of compressed bytes.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The length of the decompressed final dimension.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_starts</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of starting bytes in the bytestream.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_nbytes</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of number of bytes in each stream.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_offsets</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of offsets, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_gains</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of gains, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>first_stream_sample</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The first sample of every stream to decompress.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>last_stream_sample</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The last sample of every stream to decompress.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>is_int64</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the compressed stream contains 64bit integers.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>no_flatten</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, for single-stream arrays, leave the leading
dimension of (1,) in the result.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The output array.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/decompress.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">array_decompress</span><span class="p">(</span>
    <span class="n">compressed</span><span class="p">,</span>
    <span class="n">stream_size</span><span class="p">,</span>
    <span class="n">stream_starts</span><span class="p">,</span>
    <span class="n">stream_nbytes</span><span class="p">,</span>
    <span class="n">stream_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">stream_gains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">first_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_int64</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decompress a FLAC encoded array and restore original data type.</span>

<span class="sd">    If both `stream_gains` and `stream_offsets` are specified, the output will be</span>
<span class="sd">    floating point data.  If neither is specified, the output will be integer data.</span>
<span class="sd">    It is an error to specify only one of those options.</span>

<span class="sd">    The compressed byte stream might contain either int32 or int64 data, and the calling</span>
<span class="sd">    code is responsible for tracking this.  The `is_int64` parameter should be set to</span>
<span class="sd">    True if the byte stream contains 64bit integers.</span>

<span class="sd">    To decompress a subset of samples in all streams, specify the `first_stream_sample`</span>
<span class="sd">    and `last_stream_sample` values.  None values or negative values disable this</span>
<span class="sd">    feature.</span>

<span class="sd">    Args:</span>
<span class="sd">        compressed (array):  The array of compressed bytes.</span>
<span class="sd">        stream_size (int):  The length of the decompressed final dimension.</span>
<span class="sd">        stream_starts (array):  The array of starting bytes in the bytestream.</span>
<span class="sd">        stream_nbytes (array):  The array of number of bytes in each stream.</span>
<span class="sd">        stream_offsets (array):  The array of offsets, one per stream.</span>
<span class="sd">        stream_gains (array):  The array of gains, one per stream.</span>
<span class="sd">        first_stream_sample (int):  The first sample of every stream to decompress.</span>
<span class="sd">        last_stream_sample (int):  The last sample of every stream to decompress.</span>
<span class="sd">        is_int64 (bool):  If True, the compressed stream contains 64bit integers.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>
<span class="sd">        no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">            dimension of (1,) in the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (array): The output array.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">arr</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">array_decompress_slice</span><span class="p">(</span>
        <span class="n">compressed</span><span class="p">,</span>
        <span class="n">stream_size</span><span class="p">,</span>
        <span class="n">stream_starts</span><span class="p">,</span>
        <span class="n">stream_nbytes</span><span class="p">,</span>
        <span class="n">stream_offsets</span><span class="o">=</span><span class="n">stream_offsets</span><span class="p">,</span>
        <span class="n">stream_gains</span><span class="o">=</span><span class="n">stream_gains</span><span class="p">,</span>
        <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">first_stream_sample</span><span class="o">=</span><span class="n">first_stream_sample</span><span class="p">,</span>
        <span class="n">last_stream_sample</span><span class="o">=</span><span class="n">last_stream_sample</span><span class="p">,</span>
        <span class="n">is_int64</span><span class="o">=</span><span class="n">is_int64</span><span class="p">,</span>
        <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
        <span class="n">no_flatten</span><span class="o">=</span><span class="n">no_flatten</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">arr</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="flacarray.decompress.array_decompress_slice" class="doc doc-heading">
<code class="doc-symbol doc-symbol-heading doc-symbol-function"></code>            <code class="highlight language-python"><span class="n">flacarray</span><span class="o">.</span><span class="n">decompress</span><span class="o">.</span><span class="n">array_decompress_slice</span><span class="p">(</span><span class="n">compressed</span><span class="p">,</span> <span class="n">stream_size</span><span class="p">,</span> <span class="n">stream_starts</span><span class="p">,</span> <span class="n">stream_nbytes</span><span class="p">,</span> <span class="n">stream_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">stream_gains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">first_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">is_int64</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

</h3>


    <div class="doc doc-contents first">

        <p>Decompress a slice of a FLAC encoded array and restore original data type.</p>
<p>If both <code>stream_gains</code> and <code>stream_offsets</code> are specified, the output will be
floating point data.  If neither is specified, the output will be integer data.
It is an error to specify only one of those options.</p>
<p>The compressed byte stream might contain either int32 or int64 data, and the calling
code is responsible for tracking this.  The <code>is_int64</code> parameter should be set to
True if the byte stream contains 64bit integers.</p>
<p>To decompress a subset of samples in all streams, specify the <code>first_stream_sample</code>
and <code>last_stream_sample</code> values.  None values or negative values disable this
feature.</p>
<p>To decompress a subset of streams, pass a boolean array to the <code>keep</code> argument.
This should have the same shape as the <code>starts</code> array.  Only streams with a True
value in the <code>keep</code> array will be decompressed.</p>
<p>If the <code>keep</code> array is specified, the output tuple will contain the 2D array of
streams that were kept, as well as a list of tuples indicating the original array
indices for each stream in the output.  If the <code>keep</code> array is None, the output
tuple will contain an array with the original N-dimensional leading array shape
and the trailing number of samples.  The second element of the tuple will be None.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>compressed</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of compressed bytes.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_size</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The length of the decompressed final dimension.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_starts</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of starting bytes in the bytestream.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_nbytes</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of number of bytes in each stream.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_offsets</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of offsets, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stream_gains</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The array of gains, one per stream.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>keep</code>
            </td>
            <td>
                  <code><span title="flacarray.array">array</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Bool array of streams to keep in the decompression.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>first_stream_sample</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The first sample of every stream to decompress.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>last_stream_sample</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The last sample of every stream to decompress.</p>
              </div>
            </td>
            <td>
                  <code>None</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>is_int64</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, the compressed stream contains 64bit integers.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>use_threads</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, use OpenMP threads to parallelize decoding.
This is only beneficial for large arrays.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>no_flatten</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>If True, for single-stream arrays, leave the leading
dimension of (1,) in the result.</p>
              </div>
            </td>
            <td>
                  <code>False</code>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                  <code><span title="tuple">tuple</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>The (output array, list of stream indices).</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>flacarray/decompress.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@function_timer</span>
<span class="k">def</span><span class="w"> </span><span class="nf">array_decompress_slice</span><span class="p">(</span>
    <span class="n">compressed</span><span class="p">,</span>
    <span class="n">stream_size</span><span class="p">,</span>
    <span class="n">stream_starts</span><span class="p">,</span>
    <span class="n">stream_nbytes</span><span class="p">,</span>
    <span class="n">stream_offsets</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">stream_gains</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">keep</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">first_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_stream_sample</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">is_int64</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">use_threads</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="n">no_flatten</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Decompress a slice of a FLAC encoded array and restore original data type.</span>

<span class="sd">    If both `stream_gains` and `stream_offsets` are specified, the output will be</span>
<span class="sd">    floating point data.  If neither is specified, the output will be integer data.</span>
<span class="sd">    It is an error to specify only one of those options.</span>

<span class="sd">    The compressed byte stream might contain either int32 or int64 data, and the calling</span>
<span class="sd">    code is responsible for tracking this.  The `is_int64` parameter should be set to</span>
<span class="sd">    True if the byte stream contains 64bit integers.</span>

<span class="sd">    To decompress a subset of samples in all streams, specify the `first_stream_sample`</span>
<span class="sd">    and `last_stream_sample` values.  None values or negative values disable this</span>
<span class="sd">    feature.</span>

<span class="sd">    To decompress a subset of streams, pass a boolean array to the `keep` argument.</span>
<span class="sd">    This should have the same shape as the `starts` array.  Only streams with a True</span>
<span class="sd">    value in the `keep` array will be decompressed.</span>

<span class="sd">    If the `keep` array is specified, the output tuple will contain the 2D array of</span>
<span class="sd">    streams that were kept, as well as a list of tuples indicating the original array</span>
<span class="sd">    indices for each stream in the output.  If the `keep` array is None, the output</span>
<span class="sd">    tuple will contain an array with the original N-dimensional leading array shape</span>
<span class="sd">    and the trailing number of samples.  The second element of the tuple will be None.</span>

<span class="sd">    Args:</span>
<span class="sd">        compressed (array):  The array of compressed bytes.</span>
<span class="sd">        stream_size (int):  The length of the decompressed final dimension.</span>
<span class="sd">        stream_starts (array):  The array of starting bytes in the bytestream.</span>
<span class="sd">        stream_nbytes (array):  The array of number of bytes in each stream.</span>
<span class="sd">        stream_offsets (array):  The array of offsets, one per stream.</span>
<span class="sd">        stream_gains (array):  The array of gains, one per stream.</span>
<span class="sd">        keep (array):  Bool array of streams to keep in the decompression.</span>
<span class="sd">        first_stream_sample (int):  The first sample of every stream to decompress.</span>
<span class="sd">        last_stream_sample (int):  The last sample of every stream to decompress.</span>
<span class="sd">        is_int64 (bool):  If True, the compressed stream contains 64bit integers.</span>
<span class="sd">        use_threads (bool):  If True, use OpenMP threads to parallelize decoding.</span>
<span class="sd">            This is only beneficial for large arrays.</span>
<span class="sd">        no_flatten (bool):  If True, for single-stream arrays, leave the leading</span>
<span class="sd">            dimension of (1,) in the result.</span>

<span class="sd">    Returns:</span>
<span class="sd">        (tuple): The (output array, list of stream indices).</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">first_stream_sample</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">first_stream_sample</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
    <span class="k">if</span> <span class="n">last_stream_sample</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">last_stream_sample</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>

    <span class="c1"># If we have one stream, ensure that our auxiliary data are arrays</span>
    <span class="n">is_scalar</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="k">if</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">stream_starts</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="ow">or</span>
        <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">stream_starts</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">stream_starts</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">):</span>
        <span class="c1"># This is a scalar</span>
        <span class="n">is_scalar</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">stream_starts</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_starts</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="n">stream_nbytes</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_nbytes</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">stream_offsets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># We have float values</span>
            <span class="k">if</span> <span class="n">is_int64</span><span class="p">:</span>
                <span class="n">stream_offsets</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_offsets</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
                <span class="n">stream_gains</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_gains</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">stream_offsets</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_offsets</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">stream_gains</span> <span class="o">=</span> <span class="n">ensure_one_element</span><span class="p">(</span><span class="n">stream_gains</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">starts</span><span class="p">,</span> <span class="n">nbytes</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">keep_select</span><span class="p">(</span><span class="n">keep</span><span class="p">,</span> <span class="n">stream_starts</span><span class="p">,</span> <span class="n">stream_nbytes</span><span class="p">)</span>
    <span class="n">offsets</span> <span class="o">=</span> <span class="n">select_keep_indices</span><span class="p">(</span><span class="n">stream_offsets</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
    <span class="n">gains</span> <span class="o">=</span> <span class="n">select_keep_indices</span><span class="p">(</span><span class="n">stream_gains</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">stream_offsets</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stream_gains</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># This is floating point data.</span>
            <span class="n">idata</span> <span class="o">=</span> <span class="n">decode_flac</span><span class="p">(</span>
                <span class="n">compressed</span><span class="p">,</span>
                <span class="n">starts</span><span class="p">,</span>
                <span class="n">nbytes</span><span class="p">,</span>
                <span class="n">stream_size</span><span class="p">,</span>
                <span class="n">first_sample</span><span class="o">=</span><span class="n">first_stream_sample</span><span class="p">,</span>
                <span class="n">last_sample</span><span class="o">=</span><span class="n">last_stream_sample</span><span class="p">,</span>
                <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
                <span class="n">is_int64</span><span class="o">=</span><span class="n">is_int64</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">arr</span> <span class="o">=</span> <span class="n">int_to_float</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span> <span class="n">offsets</span><span class="p">,</span> <span class="n">gains</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;When specifying offsets, you must also provide the gains&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">stream_gains</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
                <span class="s2">&quot;When specifying gains, you must also provide the offsets&quot;</span>
            <span class="p">)</span>
        <span class="c1"># This is integer data</span>
        <span class="n">arr</span> <span class="o">=</span> <span class="n">decode_flac</span><span class="p">(</span>
            <span class="n">compressed</span><span class="p">,</span>
            <span class="n">starts</span><span class="p">,</span>
            <span class="n">nbytes</span><span class="p">,</span>
            <span class="n">stream_size</span><span class="p">,</span>
            <span class="n">first_sample</span><span class="o">=</span><span class="n">first_stream_sample</span><span class="p">,</span>
            <span class="n">last_sample</span><span class="o">=</span><span class="n">last_stream_sample</span><span class="p">,</span>
            <span class="n">use_threads</span><span class="o">=</span><span class="n">use_threads</span><span class="p">,</span>
            <span class="n">is_int64</span><span class="o">=</span><span class="n">is_int64</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">is_scalar</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">no_flatten</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">arr</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">)),</span> <span class="n">indices</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.expand", "navigation.path"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../js/print-site.js"></script>
      
        <script src="../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>